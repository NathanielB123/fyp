

a normalisation algorithm which depends on
deciding |rw|'s convertability premise cannot work.

The trick is thus: we



 confluence and that whether term

 also need confluence. The new |_‚ä¢_>_| relation definitely

The trick t


The obvious cause of our prior attempt at reduction relation failing was
that 

We clearly need a better reduction relation.






We might attempt to define a small-step reduction relation that corresponds to
this conversion relation.





\section{Normalisation}

We aim to show that this enhanced conversion relation is decidable via
the technique of strong normalisation. We define a small-step reduction
relation:

%if False
\begin{code}
infix 4 _‚ä¢_>_ 
\end{code}
%endif

\begin{code}
-- data _‚ä¢_>_ (Œû : Eqs Œì) : Tm Œì A ‚Üí Tm Œì A ‚Üí Set where
--   -- Computation
--   ‚áíŒ≤   : Œû ‚ä¢ (∆õ t) ¬∑ u  > t [ < u > ]
--   ùîπŒ≤‚ÇÅ  : Œû ‚ä¢ if TT u v  > u 
--   ùîπŒ≤‚ÇÇ  : Œû ‚ä¢ if FF u v  > v
  
--   -- Rewriting
--   eq : EqVar Œû t b ‚Üí Œû ‚ä¢ t > ‚åú b ‚åùùîπ

--   -- Monotonicity
--   ∆õ_   : Œû [ wk ]Eq  ‚ä¢ t‚ÇÅ  > t‚ÇÇ  ‚Üí Œû ‚ä¢ ∆õ t‚ÇÅ       > ∆õ t‚ÇÇ 
--   l¬∑   : Œû           ‚ä¢ t‚ÇÅ  > t‚ÇÇ  ‚Üí Œû ‚ä¢ t‚ÇÅ ¬∑ u     > t‚ÇÇ ¬∑ u
--   ¬∑r   : Œû           ‚ä¢ u‚ÇÅ  > u‚ÇÇ  ‚Üí Œû ‚ä¢ t ¬∑ u‚ÇÅ     > t ¬∑ u‚ÇÇ
--   if‚ÇÅ  : Œû           ‚ä¢ t‚ÇÅ  > t‚ÇÇ  ‚Üí Œû ‚ä¢ if t‚ÇÅ u v  > if t‚ÇÇ u v
--   if‚ÇÇ  : Œû           ‚ä¢ u‚ÇÅ  > u‚ÇÇ  ‚Üí Œû ‚ä¢ if t u‚ÇÅ v  > if t u‚ÇÇ v
--   if‚ÇÉ  : Œû           ‚ä¢ v‚ÇÅ  > v‚ÇÇ  ‚Üí Œû ‚ä¢ if t u v‚ÇÅ  > if t u v‚ÇÇ
\end{code}

% Oh I am very silly
% This reduction relation is nonsense
% The |eq| pre-condition should be |Œû ‚ä¢ t ~ ‚åú b ‚åùùîπ|

% Maybe worth positing the idea of having a reduction which simplifies the
% equational context, and then using the old rule.

% What we can say is that for completes TRSs, the above reduction relation
% is equivalent.

% The completion algorithm can be justified by having |~|-pre is SN, and then 
% only ever
% actually rewriting by completed |TRS|s!

% |~|-pre is SN by existing work
% Normalisation then works by completing every time an equation is introduced,
% and inserting |!| if the equational context is inconsistent.

Note that this recuction relation is not confluent! To stay well-founded, we
do not support rewriting from |TT|/|FF|, but there is nothing stopping 
our equational context from containing ``bad'' equations like |TT ~ FF|.

To normalise terms in arbitrary equational contexts then, we need to first
complete the set of equations into a confluent (ground) TRS, and then proceed
reducing with small-step reduction. Strong normalisation is useful here, 
as taking the fixed point of repeatedly reducing equation LHSs can be
justified by extending reduction order over equational contexts 
lexicographically.

% Todo: we have some design decisions to make here
% We could define a restricted version of |_‚ä¢_>_| which doesn't allow rewriting
% Booleans. Assuming this relation is well-founded (for any equational
% environment), justifying completion is not too hard.

% Alternatively, we could define a predicate on equation sets which guarantees
% they don't have any closed booleans on the LHS. Reduction as-is is SN
% for any such environment. We can then show how this property is decidable
% Normalisation still has to do completion so we can insert |!|s where-ever
% the equational environment is unsound (might be useful to define equality
% collapse early)

% I think I nice way to structure explanations could be: 
% This reduction relation is not SN in presense of Bool equations
% Redundant equations can obviously be removed
% Impossible equations imply equality collapse
% Therefore we can define normalisation as first completing the set of rewrites

\begin{code}
TRS : Eqs Œì ‚Üí Set

sn : TRS Œû ‚Üí ‚àÄ (t : Tm Œì A) ‚Üí SN (Œû ‚ä¢_>_) t

-- TRS defined as:
-- All LHSs irreducible
-- All LHSs neutral
--
-- From this, we can pretty easily derive no overlap/confluence


-- data TRS where
--   ‚Ä¢        : TRS (‚Ä¢ {Œì = Œì})
--   _‚ñ∑_>eq_  : TRS Œû ‚Üí {!!}
\end{code}

%if False
\begin{code}
infix 4 _‚ä¢_>Eq_ _>Eq_ 
\end{code}
%endif

\begin{code}
data _‚ä¢_>Eq_ (Œû : Eqs Œì) : Eqs Œì ‚Üí Eqs Œì ‚Üí Set

_>Eq_ : Eqs Œì ‚Üí Eqs Œì ‚Üí Set
Œ® >Eq Œ¶ = Œ® ‚ä¢ Œ® >Eq Œ¶

data _‚ä¢_>Eq_ Œû where
  vz>  : Œû ‚ä¢ t‚ÇÅ > t‚ÇÇ ‚Üí Œû ‚ä¢ Œ® ‚ñ∑ t‚ÇÅ >eq b >Eq Œ® ‚ñ∑ t‚ÇÇ >eq b
  vs>  : Œû ‚ä¢ Œ®‚ÇÅ >Eq Œ®‚ÇÇ ‚Üí Œû ‚ä¢ t‚ÇÅ ~ t‚ÇÇ ‚Üí Œû ‚ä¢ Œ®‚ÇÅ ‚ñ∑ t‚ÇÅ >eq b >Eq Œ®‚ÇÇ ‚ñ∑ t‚ÇÇ >eq b 

data SNEq (Œû : Eqs Œì) : Eqs Œì ‚Üí Set where
  ‚Ä¢    : SNEq Œû (‚Ä¢ {Œì = Œì})
  _‚ñ∑_  : SNEq Œû Œ® ‚Üí SN (Œû ‚ä¢_>_) t ‚Üí SNEq Œû (Œ® ‚ñ∑ t >eq b)

snEq : TRS Œû ‚Üí ‚àÄ Œ® ‚Üí SN (Œû ‚ä¢_>Eq_) Œ®

sn‚ñ∑   : TRS Œû ‚Üí SN (Œû ‚ä¢_>Eq_) Œ® ‚Üí SN (Œû ‚ä¢_>_) t ‚Üí SN (Œû ‚ä¢_>Eq_) (Œ® ‚ñ∑ t >eq b)
sn‚ñ∑>  : TRS Œû ‚Üí SN (Œû ‚ä¢_>Eq_) Œ®‚ÇÅ ‚Üí SN (Œû ‚ä¢_>_) t‚ÇÅ
      ‚Üí Œû ‚ä¢ Œ®‚ÇÅ ‚ñ∑ t‚ÇÅ >eq b >Eq Œ®‚ÇÇ ‚Üí SN (Œû ‚ä¢_>Eq_) Œ®‚ÇÇ

sn‚ñ∑ Œû·∂ú Œ®·¥¨ t·¥¨ = acc (sn‚ñ∑> Œû·∂ú Œ®·¥¨ t·¥¨)

sn‚ñ∑> Œû·∂ú Œ®·¥¨        (acc t·¥¨)  (vz> t>)     = sn‚ñ∑ Œû·∂ú Œ®·¥¨       (t·¥¨ t>)
sn‚ñ∑> Œû·∂ú (acc Œ®·¥¨)  t·¥¨        (vs> Œ®> t~)  = sn‚ñ∑ Œû·∂ú (Œ®·¥¨ Œ®>)  (sn Œû·∂ú _)

snSNEq  : TRS Œû ‚Üí SNEq Œû Œ® ‚Üí SN (Œû ‚ä¢_>Eq_) Œ®
snSNEq> : TRS Œû ‚Üí SNEq Œû Œ®‚ÇÅ ‚Üí Œû ‚ä¢ Œ®‚ÇÅ >Eq Œ®‚ÇÇ ‚Üí SN (Œû ‚ä¢_>Eq_) Œ®‚ÇÇ

snSNEq Œû·∂ú Œ® = acc (snSNEq> Œû·∂ú Œ®)

-- This sucks - we need to combine structural and SN order here, and I'm not
-- quite sure how to justify it...
snSNEq> Œû·∂ú (Œ® ‚ñ∑ acc t·¥¨)  (vz> t>)    = {! snSNEq Œû·∂ú (Œ® ‚ñ∑ t·¥¨ t>) !}
snSNEq> Œû·∂ú (Œ® ‚ñ∑ t·¥¨)      (vs> Œ®> t~) = sn‚ñ∑ Œû·∂ú (snSNEq> Œû·∂ú Œ® Œ®>) (sn Œû·∂ú _)
\end{code}

We have a reduction relation and potential normalisation algorithm, but 
we of course still need to prove this reduction relation is well-founded.
We do this by picking a slightly larger reduction relation that is 
slightly better-behaved.

\subsection{Spontaneous and Non-Determinsitic Reduction}

\begin{code}
data _>!_ : Tm Œì A ‚Üí Tm Œì A ‚Üí Set where
  eqTT : t >! TT
  eqFF : t >! FF
\end{code}

Proving strong normalisation of spontaneous reduction directly is possible,
but is slightly awkward due to instability under substitutions.
E.g. we have |` i >! TT|, if we then apply the substitution |TT / i| to
both sides, we are left with |TT >! TT|, which is explicitly not allowed
to ensure |TT| stays in normal form.

We therefore consider yet another reduction relation: Non-Deterministic
Reduction. The idea is to allow any |if|-expression to immediately reduce
to the left or right branch (irrespective of the scrutinee).

\begin{code}
data _>ND_ : Tm Œì A ‚Üí Tm Œì A ‚Üí Set where
  ifND‚ÇÅ  : if t u v >ND u
  ifND‚ÇÇ  : if t u v >ND v
\end{code}

It turns out that we can prove that strong normalisation w.r.t.
non-determinsitic reduction implies strong normalisation w.r.t. spontaneous
reduction. In fact, we can prove this result inside untyped lambda calculus
(removing the |ùîπ|-typed condition on spontaneous reduction. We will prove
this now.
