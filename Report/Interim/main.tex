
% \documentclass[12pt,twoside]{report}
\documentclass[
    a4paper, % Page size
    fontsize=9.5pt, % Base font size
    twoside=false, % Use different layouts for even and odd pages (in particular, if twoside=true, the margin column will be always on the outside)
	%open=any, % If twoside=true, uncomment this to force new chapters to start on any page, not only on right (odd) pages
	%chapterentrydots=true, % Uncomment to output dots from the chapter name to the page number in the table of contents
	numbers=noenddot, % Comment to output dots after chapter numbers; the most common values for this option are: enddot, noenddot and auto (see the KOMAScript documentation for an in-depth explanation)
	fontmethod=tex, % Can also use "modern" with XeLaTeX or LuaTex; "tex" is the default for PdfLaTex, and "modern" is the default for those two.
]{kaobook}

% some definitions for the title page
\newcommand{\reporttitle}{Local Rewriting in Dependent Type Theory}
\newcommand{\reportauthor}{Nathaniel Burke}
\newcommand{\supervisor}{Dr. Steffen van Bakel}
\newcommand{\reporttype}{MEng Individual Project (Interim Report)}
\newcommand{\degreetype}{MEng Computing} 

% load some definitions and default packages
\input{includes}

% 1.5 Column formatting
% \usepackage[a4paper,hmargin=2.8cm,vmargin=2.0cm,includeheadfoot]{geometry}

% load some macros
\input{notation}

\input{utilities/kaoextensions}


%% ODER: format ==         = "\mathrel{==}"
%% ODER: format /=         = "\neq "
%
%
\makeatletter
\@ifundefined{lhs2tex.lhs2tex.sty.read}%
  {\@namedef{lhs2tex.lhs2tex.sty.read}{}%
   \newcommand\SkipToFmtEnd{}%
   \newcommand\EndFmtInput{}%
   \long\def\SkipToFmtEnd#1\EndFmtInput{}%
  }\SkipToFmtEnd

\newcommand\ReadOnlyOnce[1]{\@ifundefined{#1}{\@namedef{#1}{}}\SkipToFmtEnd}
\usepackage{amstext}
\usepackage{amssymb}
\usepackage{stmaryrd}
\DeclareFontFamily{OT1}{cmtex}{}
\DeclareFontShape{OT1}{cmtex}{m}{n}
  {<5><6><7><8>cmtex8
   <9>cmtex9
   <10><10.95><12><14.4><17.28><20.74><24.88>cmtex10}{}
\DeclareFontShape{OT1}{cmtex}{m}{it}
  {<-> ssub * cmtt/m/it}{}
\newcommand{\texfamily}{\fontfamily{cmtex}\selectfont}
\DeclareFontShape{OT1}{cmtt}{bx}{n}
  {<5><6><7><8>cmtt8
   <9>cmbtt9
   <10><10.95><12><14.4><17.28><20.74><24.88>cmbtt10}{}
\DeclareFontShape{OT1}{cmtex}{bx}{n}
  {<-> ssub * cmtt/bx/n}{}
\newcommand{\tex}[1]{\text{\texfamily#1}}	% NEU

\newcommand{\Sp}{\hskip.33334em\relax}


\newcommand{\Conid}[1]{\mathit{#1}}
\newcommand{\Varid}[1]{\mathit{#1}}
\newcommand{\anonymous}{\kern0.06em \vbox{\hrule\@width.5em}}
\newcommand{\plus}{\mathbin{+\!\!\!+}}
\newcommand{\bind}{\mathbin{>\!\!\!>\mkern-6.7mu=}}
\newcommand{\rbind}{\mathbin{=\mkern-6.7mu<\!\!\!<}}% suggested by Neil Mitchell
\newcommand{\sequ}{\mathbin{>\!\!\!>}}
\renewcommand{\leq}{\leqslant}
\renewcommand{\geq}{\geqslant}
\usepackage{polytable}

%mathindent has to be defined
\@ifundefined{mathindent}%
  {\newdimen\mathindent\mathindent\leftmargini}%
  {}%

\def\resethooks{%
  \global\let\SaveRestoreHook\empty
  \global\let\ColumnHook\empty}
\newcommand*{\savecolumns}[1][default]%
  {\g@addto@macro\SaveRestoreHook{\savecolumns[#1]}}
\newcommand*{\restorecolumns}[1][default]%
  {\g@addto@macro\SaveRestoreHook{\restorecolumns[#1]}}
\newcommand*{\aligncolumn}[2]%
  {\g@addto@macro\ColumnHook{\column{#1}{#2}}}

\resethooks

\newcommand{\onelinecommentchars}{\quad-{}- }
\newcommand{\commentbeginchars}{\enskip\{-}
\newcommand{\commentendchars}{-\}\enskip}

\newcommand{\visiblecomments}{%
  \let\onelinecomment=\onelinecommentchars
  \let\commentbegin=\commentbeginchars
  \let\commentend=\commentendchars}

\newcommand{\invisiblecomments}{%
  \let\onelinecomment=\empty
  \let\commentbegin=\empty
  \let\commentend=\empty}

\visiblecomments

\newlength{\blanklineskip}
\setlength{\blanklineskip}{0.66084ex}

\newcommand{\hsindent}[1]{\quad}% default is fixed indentation
\let\hspre\empty
\let\hspost\empty
\newcommand{\NB}{\textbf{NB}}
\newcommand{\Todo}[1]{$\langle$\textbf{To do:}~#1$\rangle$}

\EndFmtInput
\makeatother
%
%%include polycode.fmt
%
%
%
%
%
% This package provides two environments suitable to take the place
% of hscode, called "plainhscode" and "arrayhscode". 
%
% The plain environment surrounds each code block by vertical space,
% and it uses \abovedisplayskip and \belowdisplayskip to get spacing
% similar to formulas. Note that if these dimensions are changed,
% the spacing around displayed math formulas changes as well.
% All code is indented using \leftskip.
%
% Changed 19.08.2004 to reflect changes in colorcode. Should work with
% CodeGroup.sty.
%
\ReadOnlyOnce{polycode.fmt}%
\makeatletter

\newcommand{\hsnewpar}[1]%
  {{\parskip=0pt\parindent=0pt\par\vskip #1\noindent}}

% can be used, for instance, to redefine the code size, by setting the
% command to \small or something alike
\newcommand{\hscodestyle}{}

% The command \sethscode can be used to switch the code formatting
% behaviour by mapping the hscode environment in the subst directive
% to a new LaTeX environment.

\newcommand{\sethscode}[1]%
  {\expandafter\let\expandafter\hscode\csname #1\endcsname
   \expandafter\let\expandafter\endhscode\csname end#1\endcsname}

% "compatibility" mode restores the non-polycode.fmt layout.

\newenvironment{compathscode}%
  {\par\noindent
   \advance\leftskip\mathindent
   \hscodestyle
   \let\\=\@normalcr
   \let\hspre\(\let\hspost\)%
   \pboxed}%
  {\endpboxed\)%
   \par\noindent
   \ignorespacesafterend}

\newcommand{\compaths}{\sethscode{compathscode}}

% "plain" mode is the proposed default.
% It should now work with \centering.
% This required some changes. The old version
% is still available for reference as oldplainhscode.

\newenvironment{plainhscode}%
  {\hsnewpar\abovedisplayskip
   \advance\leftskip\mathindent
   \hscodestyle
   \let\hspre\(\let\hspost\)%
   \pboxed}%
  {\endpboxed%
   \hsnewpar\belowdisplayskip
   \ignorespacesafterend}

\newenvironment{oldplainhscode}%
  {\hsnewpar\abovedisplayskip
   \advance\leftskip\mathindent
   \hscodestyle
   \let\\=\@normalcr
   \(\pboxed}%
  {\endpboxed\)%
   \hsnewpar\belowdisplayskip
   \ignorespacesafterend}

% Here, we make plainhscode the default environment.

\newcommand{\plainhs}{\sethscode{plainhscode}}
\newcommand{\oldplainhs}{\sethscode{oldplainhscode}}
\plainhs

% The arrayhscode is like plain, but makes use of polytable's
% parray environment which disallows page breaks in code blocks.

\newenvironment{arrayhscode}%
  {\hsnewpar\abovedisplayskip
   \advance\leftskip\mathindent
   \hscodestyle
   \let\\=\@normalcr
   \(\parray}%
  {\endparray\)%
   \hsnewpar\belowdisplayskip
   \ignorespacesafterend}

\newcommand{\arrayhs}{\sethscode{arrayhscode}}

% The mathhscode environment also makes use of polytable's parray 
% environment. It is supposed to be used only inside math mode 
% (I used it to typeset the type rules in my thesis).

\newenvironment{mathhscode}%
  {\parray}{\endparray}

\newcommand{\mathhs}{\sethscode{mathhscode}}

% texths is similar to mathhs, but works in text mode.

\newenvironment{texthscode}%
  {\(\parray}{\endparray\)}

\newcommand{\texths}{\sethscode{texthscode}}

% The framed environment places code in a framed box.

\def\codeframewidth{\arrayrulewidth}
\RequirePackage{calc}

\newenvironment{framedhscode}%
  {\parskip=\abovedisplayskip\par\noindent
   \hscodestyle
   \arrayrulewidth=\codeframewidth
   \tabular{@{}|p{\linewidth-2\arraycolsep-2\arrayrulewidth-2pt}|@{}}%
   \hline\framedhslinecorrect\\{-1.5ex}%
   \let\endoflinesave=\\
   \let\\=\@normalcr
   \(\pboxed}%
  {\endpboxed\)%
   \framedhslinecorrect\endoflinesave{.5ex}\hline
   \endtabular
   \parskip=\belowdisplayskip\par\noindent
   \ignorespacesafterend}

\newcommand{\framedhslinecorrect}[2]%
  {#1[#2]}

\newcommand{\framedhs}{\sethscode{framedhscode}}

% The inlinehscode environment is an experimental environment
% that can be used to typeset displayed code inline.

\newenvironment{inlinehscode}%
  {\(\def\column##1##2{}%
   \let\>\undefined\let\<\undefined\let\\\undefined
   \newcommand\>[1][]{}\newcommand\<[1][]{}\newcommand\\[1][]{}%
   \def\fromto##1##2##3{##3}%
   \def\nextline{}}{\) }%

\newcommand{\inlinehs}{\sethscode{inlinehscode}}

% The joincode environment is a separate environment that
% can be used to surround and thereby connect multiple code
% blocks.

\newenvironment{joincode}%
  {\let\orighscode=\hscode
   \let\origendhscode=\endhscode
   \def\endhscode{\def\hscode{\endgroup\def\@currenvir{hscode}\\}\begingroup}
   %\let\SaveRestoreHook=\empty
   %\let\ColumnHook=\empty
   %\let\resethooks=\empty
   \orighscode\def\hscode{\endgroup\def\@currenvir{hscode}}}%
  {\origendhscode
   \global\let\hscode=\orighscode
   \global\let\endhscode=\origendhscode}%

\makeatother
\EndFmtInput
%
%
\ReadOnlyOnce{agda_tweaked.fmt}%


\RequirePackage[T1]{fontenc}
\RequirePackage[utf8]{inputenc}
% \RequirePackage{ucs}
\RequirePackage{newunicodechar}
\RequirePackage{amsfonts}

\providecommand\mathbbm{\mathbb}

% TODO: Define more of these ...
% \DeclareUnicodeCharacter{737}{\textsuperscript{l}}
% \DeclareUnicodeCharacter{8718}{\ensuremath{\blacksquare}}
% \DeclareUnicodeCharacter{8759}{::}
% \DeclareUnicodeCharacter{9669}{\ensuremath{\triangleleft}}
% \DeclareUnicodeCharacter{8799}{\ensuremath{\stackrel{\scriptscriptstyle ?}{=}}}
% \DeclareUnicodeCharacter{10214}{\ensuremath{\llbracket}}
% \DeclareUnicodeCharacter{10215}{\ensuremath{\rrbracket}}

% TODO: This is in general not a good idea.
\providecommand\textepsilon{$\epsilon$}
\providecommand\textmu{$\mu$}


%Actually, varsyms should not occur in Agda output.

% TODO: Make this configurable. IMHO, italics doesn't work well
% for Agda code.

\renewcommand\Varid[1]{\mathord{\textsf{#1}}}
\let\Conid\Varid
\newcommand\Keyword[1]{\textsf{\textbf{#1}}}
\EndFmtInput

% "\newunicodechar" and "%format" do similar but not exactly the same thing:
% - "\newunicodechar" works outside of code blocks and is always required for 
%   any characters not in "[utf8]{inputenc}". I'm not entirely sure why but 
%   perhaps it errors before "%format" fires.
%   Note that traditionally one would use "[utf8x]{inputenc}" which declares
%   WAY more unicode characters, but this is sadly incompatible with biblatex...
% - "%format" can replace strings of characters as well as individual ones (in
%   fact, it only replaces if the entire LHS word matches) and overrides 
%   "newunicodechar" (specifically, "\newunicodechar" doesn't actually replace 
%   the unicode character - it only alters how it is displayed, while 
%   "%format" actually does a replacement)

% Based on this distinction, I am organising this file as follows:
% - "\newunicodechar" declarations are intended to define as-close-as-possible
%   translations to the original unicode symbol (even if we might actually
%   desire it to be displayed a slightly different way in the final .pdf)
%   i.e. "\newunicodechar"s basically should never change.
% - "%format" declarations deal with fixing kerning on sequences of unicode, and
%   perform aesthetic replacements (for example, removing the bar from "ƛ")

% The main downside of this approach that I can think of is that inconsistencies
% due to words not matching exactly can crop up silently (e.g. one could 
% "%format ƛ λ" but forget "%format ƛ_ λ_"). I am hoping that ctrl+f-ing the
% output "main.tex" file for unreplaced characters will be a good-enough
% solution here.

%seperation 2

\newunicodechar{β}{$\beta$}
\newunicodechar{δ}{$\delta$}
\newunicodechar{σ}{$\sigma$}
\newunicodechar{ξ}{$\xi$}
\newunicodechar{λ}{$\lambda$}
\newunicodechar{ƛ}{$\lambdabar$}
\newunicodechar{η}{$\eta$}
\newunicodechar{ε}{$\varepsilon$}
\newunicodechar{Γ}{$\Gamma$}
\newunicodechar{Δ}{$\Delta$}
\newunicodechar{Π}{$\Pi$}

\newunicodechar{∀}{$\forall$}
\newunicodechar{≡}{$\equiv$}
\newunicodechar{⇒}{$\Rightarrow$}
\newunicodechar{⊎}{$\uplus$}
\newunicodechar{⊤}{$\top$}
\newunicodechar{⊥}{$\bot$}
\newunicodechar{⊢}{$\vdash$}
\newunicodechar{∘}{$\circ$}
\newunicodechar{∎}{$\blacksquare$}

\newunicodechar{𝔹}{$\mathbb{B}$}
\newunicodechar{ℕ}{$\mathbb{N}$}
\newunicodechar{ℤ}{$\mathbb{Z}$}

\newunicodechar{⊔}{$\sqcup$}
\newunicodechar{↦}{$\mapsto$}
\newunicodechar{⟶}{$\longrightarrow$}

\newunicodechar{∞}{$\infty$}
\newunicodechar{≥}{$\geq$}

\newunicodechar{₁}{$_{1}$}
\newunicodechar{₂}{$_{2}$}
\newunicodechar{₃}{$_{3}$}
\newunicodechar{ᵢ}{$_{i}$}
\newunicodechar{ₙ}{$_{n}$}

% \newunicodechar{¹}{$^{1}$}
\newunicodechar{ᵉ}{$^{e}$}
\newunicodechar{⁻}{$^{-}$}
\newunicodechar{⁺}{$^{+}$}
\newunicodechar{ᶠ}{$_{f}$}
\newunicodechar{ⁱ}{$^{i}$}
\newunicodechar{ⁿ}{$^{n}$}
\newunicodechar{∙}{$\bullet$}

\newunicodechar{′}{$'$}






% load title page
\begin{document}

\pagelayout{wide}

\input{titlepage}

% page numbering etc.
\pagenumbering{roman}
\clearpage{\pagestyle{empty}\cleardoublepage}
\setcounter{page}{1}
% \pagestyle{fancy}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{abstract}
% Your abstract.
% \end{abstract}

% \cleardoublepage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \section*{Acknowledgments}
% Comment this out if not needed.

% \clearpage{\pagestyle{empty}\cleardoublepage}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%--- table of contents
% \fancyhead[RE,LO]{\sffamily {Table of Contents}}
\tableofcontents 

\clearpage{\pagestyle{empty}\cleardoublepage}
\pagenumbering{arabic}
\setcounter{page}{1}
% \fancyhead[LE,RO]{\slshape \rightmark}
% \fancyhead[LO,RE]{\slshape \leftmark}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\mainmatter % Denotes the start of the main document content, resets page numbering and uses arabic numbers
\setchapterstyle{kao} % Choose the default chapter heading style
\pagelayout{margin}


\setchapterpreamble[u]{\margintoc}

\chapter{Introduction and Motivation}
\labch{introduction}

Dependent pattern matching is the common extension of pattern matching to 
dependently-typed programming languages
\sidecite[*6]{coquand1992pattern}, \sidecite[*8]{cockx2017dependent},
where on top of acting as syntax sugar for eliminating inductively-defined
types, in the bodies of matches, each matched-on variable ("scrutinee") is 
substituted for the corresponding pattern everywhere in the typing context.

It is this substituting that enables taking advantage of information learned
over the course of a match. This allows, for example, defining equality testing
functions that return actual evidence of the result of the test.
\sideremark[*2]{
In this report, our code snippets will generally follow Agda 
\cite{norell2007towards} syntax (in fact,
this entire report is written in literate Agda!), but we take some liberties
when typesetting. For example, writing $\forall$s as $\Pi$s and swapping 
the equality
symbols \ensuremath{\anonymous \!=\!\anonymous } and \ensuremath{\anonymous \!\equiv\!\anonymous } to align with their conventional meanings
in on-paper type theory.}

\begin{example}[Boolean Equality Testing] \phantom{a}
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{13}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[B]{}\Varid{test}\;\mathbin{:}\;\Pi\;(\Varid{b}\;\mathbin{:}\;\Conid{Bool})\;\Varid{→}\;(\Varid{b}\;=\;\Varid{true})\;+\;(\Varid{b}\;=\;\Varid{false}){}\<[E]%
\\
\>[B]{}\Varid{test}\;\Varid{true}\;{}\<[13]%
\>[13]{}\colonequiv\;\Varid{inl}\;\Varid{refl}{}\<[E]%
\\
\>[B]{}\Varid{test}\;\Varid{false}\;{}\<[13]%
\>[13]{}\colonequiv\;\Varid{inr}\;\Varid{refl}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{example}

Where \ensuremath{\anonymous \!=\!\anonymous } is the identity type introduced with reflexivity \ensuremath{\Varid{refl}\;\mathbin{:}\;\Varid{x}\;=\;\Varid{x}} and
\ensuremath{\Conid{A}\;+\;\Conid{B}} is a sum type, introduced with injections \ensuremath{\Varid{inl}\;\mathbin{:}\;\Conid{A}\;\Varid{→}\;\Conid{A}\;+\;\Conid{B}} and 
\ensuremath{\Varid{inr}\;\mathbin{:}\;\Conid{B}\;\Varid{→}\;\Conid{A}\;+\;\Conid{B}}. 

Note that in the \ensuremath{\Varid{test}\;\Varid{true}} branch, for example,
the substitutions \ensuremath{\Varid{true}\;\mathbin{/}\;\Varid{b}} and \ensuremath{\Varid{true}\;\mathbin{/}\;\Varid{b}} are applied to the context,
refining the goal type to \ensuremath{(\Varid{true}\;=\;\Varid{true})\;+\;(\Varid{true}\;=\;\Varid{false})}, at which \ensuremath{\Varid{inl}\;\Varid{refl}} 
typechecks successfully.

In mainstream functional programming languages, it is common to allow pattern
matching not just on the direct arguments of a function, but also on arbitrary
expressions (e.g. via \ensuremath{\Varid{case}\;\Varid{...}\;\Varid{of}\;\Varid{...}} expressions). Extending dependent pattern-matching
accordingly would have direct utility: consider this concise proof that for
any boolean function \ensuremath{\Varid{f}\;\mathbin{:}\;\Conid{Bool}\;\Varid{→}\;\Conid{Bool}}, \ensuremath{\Varid{f}\;\Varid{b}\;=\;\Varid{f}\;(\Varid{f}\;(\Varid{f}\;\Varid{b}))}:
\sideremark{This example is originally from the Agda mailing list \cite
{altenkirch2009smart}.}.

\begin{example}[\ensuremath{\Varid{f}\;\Varid{b}\;=\;\Varid{f}\;(\Varid{f}\;(\Varid{f}\;\Varid{b}))}, Concisely] \phantom{a}
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{5}{@{}>{\hspre}l<{\hspost}@{}}%
\column{10}{@{}>{\hspre}l<{\hspost}@{}}%
\column{12}{@{}>{\hspre}l<{\hspost}@{}}%
\column{21}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[B]{}\Varid{bool-lemma}\;\mathbin{:}\;\Pi\;(\Varid{f}\;\mathbin{:}\;\Conid{Bool}\;\Varid{→}\;\Conid{Bool})\;(\Varid{b}\;\mathbin{:}\;\Conid{Bool})\;\Varid{→}\;\Varid{f}\;\Varid{b}\;=\;\Varid{f}\;(\Varid{f}\;(\Varid{f}\;\Varid{b})){}\<[E]%
\\
\>[B]{}\Varid{bool-lemma}\;\Varid{f}\;\Varid{true}\;{}\<[21]%
\>[21]{}\colonequiv\;\Varid{case}\;\Varid{f}\;\Varid{true}\;\Varid{of}\;{}\<[E]%
\\
\>[B]{}\hsindent{3}{}\<[3]%
\>[3]{}\Varid{true}\;{}\<[10]%
\>[10]{}\Varid{→}\;\Varid{refl}\;{}\<[E]%
\\
\>[B]{}\hsindent{3}{}\<[3]%
\>[3]{}\Varid{false}\;{}\<[10]%
\>[10]{}\Varid{→}\;\Varid{case}\;\Varid{f}\;\Varid{false}\;\Varid{of}\;{}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\Varid{true}\;{}\<[12]%
\>[12]{}\Varid{→}\;\Varid{refl}\;{}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\Varid{false}\;{}\<[12]%
\>[12]{}\Varid{→}\;\Varid{refl}{}\<[E]%
\\
\>[B]{}\Varid{bool-lemma}\;\Varid{f}\;\Varid{false}\;{}\<[21]%
\>[21]{}\colonequiv\;\Varid{case}\;\Varid{f}\;\Varid{false}\;\Varid{of}\;{}\<[E]%
\\
\>[B]{}\hsindent{3}{}\<[3]%
\>[3]{}\Varid{true}\;{}\<[10]%
\>[10]{}\Varid{→}\;\Varid{case}\;\Varid{f}\;\Varid{true}\;{}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\Varid{true}\;{}\<[12]%
\>[12]{}\Varid{→}\;\Varid{refl}\;{}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\Varid{false}\;{}\<[12]%
\>[12]{}\Varid{→}\;\Varid{refl}\;{}\<[E]%
\\
\>[B]{}\hsindent{3}{}\<[3]%
\>[3]{}\Varid{false}\;{}\<[10]%
\>[10]{}\Varid{→}\;\Varid{refl}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{example}

Unfortunately, mainstream proof assistants generally do not support such a
construct
\remarknote{Some proof assistants do allow matching on expressions to some
extent via "\ensuremath{\Keyword{with}}-abstractions" \cite{mcbride2004view}, \cite{agda2024with}. 
We will cover why this feature is not quite satisfactory (including for this 
example) in \refch{background}.}, and we are instead forced to do the 
equational reasoning manually:
\pagebreak
\phantom{a}
\sideremark{We can shorten these equational proofs via "code golfing"
instead of using the more readable equational-reasoning syntax provided 
by the Agda standard library \cite{2024eqreasoning}, but for example,
the third case reduces down to \ensuremath{\Varid{p}\;\Varid{∙}\;\Varid{sym}\;(\Varid{cong}\;\Varid{f}\;(\Varid{cong}\;\Varid{f}\;\Varid{p}\;\Varid{∙}\;\Varid{q})\;\Varid{∙}\;\Varid{q})} - still
pretty complicated! }
\begin{example}[\ensuremath{\Varid{f}\;\Varid{b}\;=\;\Varid{f}\;(\Varid{f}\;(\Varid{f}\;\Varid{b}))}, Manually] \phantom{a}
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{4}{@{}>{\hspre}l<{\hspost}@{}}%
\column{14}{@{}>{\hspre}l<{\hspost}@{}}%
\column{22}{@{}>{\hspre}l<{\hspost}@{}}%
\column{25}{@{}>{\hspre}l<{\hspost}@{}}%
\column{31}{@{}>{\hspre}l<{\hspost}@{}}%
\column{40}{@{}>{\hspre}l<{\hspost}@{}}%
\column{43}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[B]{}\Varid{bool-lemma′}\;{}\<[14]%
\>[14]{}\mathbin{:}\;\Pi\;(\Varid{f}\;\mathbin{:}\;\Conid{Bool}\;\Varid{→}\;\Conid{Bool})\;(\Varid{b}\;\mathbin{:}\;\Conid{Bool})\;{}\<[E]%
\\
\>[14]{}\Varid{→}\;\Varid{f}\;\Varid{true}\;{}\<[25]%
\>[25]{}=\;\Varid{true}\;+\;\Varid{f}\;\Varid{true}\;{}\<[43]%
\>[43]{}=\;\Varid{false}\;{}\<[E]%
\\
\>[14]{}\Varid{→}\;\Varid{f}\;\Varid{false}\;{}\<[25]%
\>[25]{}=\;\Varid{true}\;+\;\Varid{f}\;\Varid{false}\;{}\<[43]%
\>[43]{}=\;\Varid{false}\;{}\<[E]%
\\
\>[14]{}\Varid{→}\;\Varid{f}\;\Varid{b}\;=\;\Varid{f}\;(\Varid{f}\;(\Varid{f}\;\Varid{b})){}\<[E]%
\\
\>[B]{}\Varid{bool-lemma′}\;\Varid{f}\;\Varid{true}\;{}\<[22]%
\>[22]{}(\Varid{inl}\;\Varid{p})\;{}\<[31]%
\>[31]{}\Varid{q}\;{}\<[40]%
\>[40]{}\colonequiv\;{}\<[E]%
\\
\>[B]{}\hsindent{3}{}\<[3]%
\>[3]{}\Varid{f}\;\Varid{true}\;{}\<[E]%
\\
\>[B]{}\hsindent{3}{}\<[3]%
\>[3]{}=\textit{by}\;\langle\;\Varid{sym}\;(\Varid{cong}\;\Varid{f}\;\Varid{p})\;\Varid{⟩}\;{}\<[E]%
\\
\>[B]{}\hsindent{3}{}\<[3]%
\>[3]{}\Varid{f}\;(\Varid{f}\;\Varid{true})\;{}\<[E]%
\\
\>[B]{}\hsindent{3}{}\<[3]%
\>[3]{}=\textit{by}\;\langle\;\Varid{sym}\;(\Varid{cong}\;(\Varid{f}\;\Varid{∘}\;\Varid{f})\;\Varid{p})\;\Varid{⟩}\;{}\<[E]%
\\
\>[B]{}\hsindent{3}{}\<[3]%
\>[3]{}\Varid{f}\;(\Varid{f}\;(\Varid{f}\;\Varid{true}))\;\Varid{∎}{}\<[E]%
\\
\>[B]{}\Varid{bool-lemma′}\;\Varid{f}\;\Varid{true}\;{}\<[22]%
\>[22]{}(\Varid{inr}\;\Varid{p})\;{}\<[31]%
\>[31]{}(\Varid{inl}\;\Varid{q})\;{}\<[40]%
\>[40]{}\colonequiv\;{}\<[E]%
\\
\>[B]{}\hsindent{3}{}\<[3]%
\>[3]{}\Varid{f}\;\Varid{true}\;{}\<[E]%
\\
\>[B]{}\hsindent{3}{}\<[3]%
\>[3]{}=\textit{by}\;\langle\;\Varid{sym}\;(\Varid{cong}\;\Varid{f}\;\Varid{q})\;\Varid{⟩}\;{}\<[E]%
\\
\>[B]{}\hsindent{3}{}\<[3]%
\>[3]{}\Varid{f}\;(\Varid{f}\;\Varid{false})\;{}\<[E]%
\\
\>[B]{}\hsindent{3}{}\<[3]%
\>[3]{}=\textit{by}\;\langle\;\Varid{sym}\;(\Varid{cong}\;(\Varid{f}\;\Varid{∘}\;\Varid{f})\;\Varid{p})\;\Varid{⟩}\;{}\<[E]%
\\
\>[B]{}\hsindent{3}{}\<[3]%
\>[3]{}\Varid{f}\;(\Varid{f}\;(\Varid{f}\;\Varid{true}))\;\Varid{∎}{}\<[E]%
\\
\>[B]{}\Varid{bool-lemma′}\;\Varid{f}\;\Varid{true}\;{}\<[22]%
\>[22]{}(\Varid{inr}\;\Varid{p})\;{}\<[31]%
\>[31]{}(\Varid{inr}\;\Varid{q})\;{}\<[40]%
\>[40]{}\colonequiv\;{}\<[E]%
\\
\>[B]{}\hsindent{4}{}\<[4]%
\>[4]{}\Varid{f}\;\Varid{true}\;{}\<[E]%
\\
\>[B]{}\hsindent{4}{}\<[4]%
\>[4]{}=\textit{by}\;\langle\;\Varid{p}\;\Varid{⟩}\;{}\<[E]%
\\
\>[B]{}\hsindent{4}{}\<[4]%
\>[4]{}\Varid{false}\;{}\<[E]%
\\
\>[B]{}\hsindent{4}{}\<[4]%
\>[4]{}=\textit{by}\;\langle\;\Varid{sym}\;\Varid{q}\;\Varid{⟩}\;{}\<[E]%
\\
\>[B]{}\hsindent{4}{}\<[4]%
\>[4]{}\Varid{f}\;\Varid{false}\;{}\<[E]%
\\
\>[B]{}\hsindent{4}{}\<[4]%
\>[4]{}=\textit{by}\;\langle\;\Varid{sym}\;(\Varid{cong}\;\Varid{f}\;\Varid{q})\;\Varid{⟩}\;{}\<[E]%
\\
\>[B]{}\hsindent{4}{}\<[4]%
\>[4]{}\Varid{f}\;(\Varid{f}\;\Varid{false})\;{}\<[E]%
\\
\>[B]{}\hsindent{4}{}\<[4]%
\>[4]{}=\textit{by}\;\langle\;\Varid{sym}\;(\Varid{cong}\;(\Varid{f}\;\Varid{∘}\;\Varid{f})\;\Varid{p})\;\Varid{⟩}\;{}\<[E]%
\\
\>[B]{}\hsindent{4}{}\<[4]%
\>[4]{}\Varid{f}\;(\Varid{f}\;(\Varid{f}\;\Varid{true}))\;\Varid{∎}{}\<[E]%
\\
\>[B]{}\mbox{\onelinecomment  etc... (the 'false' cases are very similar)}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[B]{}\Varid{bool-lemma}\;\mathbin{:}\;\Pi\;(\Varid{f}\;\mathbin{:}\;\Conid{Bool}\;\Varid{→}\;\Conid{Bool})\;\Varid{b}\;\Varid{→}\;\Varid{f}\;\Varid{b}\;=\;\Varid{f}\;(\Varid{f}\;(\Varid{f}\;\Varid{b})){}\<[E]%
\\
\>[B]{}\Varid{bool-lemma}\;\Varid{f}\;\Varid{b}\;\colonequiv\;\Varid{bool-lemma′}\;\Varid{f}\;\Varid{b}\;(\Varid{test}\;(\Varid{f}\;\Varid{true}))\;(\Varid{test}\;(\Varid{f}\;\Varid{false})){}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{example}

The trickyness with supporting matching on arbitrary expressions is that
there
may not exist a unique unification solution between the scrutinee and pattern.
Dependent pattern matching must modify the typing context in the branch of a
match so the result is kept track of, but we cannot make \ensuremath{\Varid{f}\;\Varid{b}} equal \ensuremath{\Varid{true}}
on-the-nose by substituting individual variables, without making any 
assumptions about the behaviour of \ensuremath{\Varid{f}} on closed booleans.

This project explores type theories with local ground equational assumptions,
a setting which should enable this extended version of pattern matching.
\sideremark{We will explain this connection in detail in
\refch{background}.}
The full benefits of such a theory are perhaps non-obvious, so to motivate
this work further, we note that it is a small jump from 
extending pattern-matching in this way to a local version
of the equality reflection rule from extensional type theory (ETT), which has
potential to simplify almost all equational proofs in modern intensional
type theory (ITT) based proof assistants.

Consider the simple inductive proof that \ensuremath{\Varid{0}} is a right-identity of \ensuremath{\Conid{ℕ}\;\Varid{,}\;\Varid{\char95 +\char95 }}
(i.e. \ensuremath{\Varid{n}\;\Varid{+}\;\Varid{0}\;=\;\Varid{n}}), where \ensuremath{\Varid{\char95 +\char95 }} is addition of natural numbers defined by 
recursion on the left argument.

In the base case, it remains to prove \ensuremath{\Varid{0}\;\Varid{+}\;\Varid{0}\;=\;\Varid{0}} which is true by definition
of \ensuremath{\Varid{\char95 +\char95 }}. In the inductive case, it remains to prove \ensuremath{(\Varid{n}\;\Varid{+}\;\Varid{1})\;\Varid{+}\;\Varid{0}\;=\;\Varid{n}\;\Varid{+}\;\Varid{1}},
which can be proved via using the definition of \ensuremath{\Varid{\char95 +\char95 }} and the IH.

\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[B]{}(\Varid{n}\;\Varid{+}\;\Varid{1})\;\Varid{+}\;\Varid{0}{}\<[E]%
\\
\>[B]{}=\mbox{\onelinecomment  \textit{by} def \ensuremath{\Varid{\char95 +\char95 }} (\ensuremath{(\Varid{n}\;\Varid{+}\;\Varid{1})\;\Varid{+}\;\Varid{m}\;\equiv\;(\Varid{n}\;\Varid{+}\;\Varid{m})\;\Varid{+}\;\Varid{1}})}{}\<[E]%
\\
\>[B]{}(\Varid{n}\;\Varid{+}\;\Varid{0})\;\Varid{+}\;\Varid{1}{}\<[E]%
\\
\>[B]{}=\mbox{\onelinecomment  \textit{by} inductive hypothesis (\ensuremath{(\Varid{n}\;\Varid{+}\;\Varid{0})\;=\;\Varid{n}})}{}\<[E]%
\\
\>[B]{}\Varid{n}\;\Varid{+}\;\Varid{1}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks

Of course, in practice it is rare to articulate a proof in so much detail. In
a larger mathematical work, such a proof might be reduced to "trivial by 
induction on ℕ" or even skipped entirely.

In the Agda proof assistant, the same proof is expressed as follows:

\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{12}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[B]{}\Varid{+0}\;\mathbin{:}\;(\Varid{n}\;\mathbin{:}\;\Conid{ℕ})\;\Varid{→}\;\Varid{n}\;\Varid{+}\;\Varid{ze}\;=\;\Varid{n}{}\<[E]%
\\
\>[B]{}\Varid{+0}\;\Varid{ze}\;{}\<[12]%
\>[12]{}\colonequiv\;\Varid{refl}{}\<[E]%
\\
\>[B]{}\Varid{+0}\;(\Varid{su}\;\Varid{n})\;{}\<[12]%
\>[12]{}\colonequiv\;\Varid{cong}\;\Varid{su}\;(\Varid{+0}\;\Varid{n}){}\<[E]%
\ColumnHook
\end{hscode}\resethooks

I think it is interesting to observe what Agda (and other ITT-based proof
assistants) are willing to automate, and what they are not. For example, we
never needed to explicitly appeal to the definition of \ensuremath{\Varid{\char95 +\char95 }} - these 
simplifications were entirely automatic, justified by how Agda only allows
structurally recursive definitions (so unfolding definitions until we get stuck
must terminate). In fact, this unfolding (or β-reducing) is exactly the basis
of so-called "definitional" equality.

On the other hand, though the syntax makes it concise, we have actually had to
more detailed in one place in our Agda proof here than in our mathematical one.
'cong su' represents that in the inductive case, we cannot apply the inductive
hypothesis directly: we have \ensuremath{(\Varid{n}\;\Varid{+}\;\Varid{ze})\;=\;\Varid{n}} but need \ensuremath{\Varid{su}\;(\Varid{n}\;\Varid{+}\;\Varid{ze})\;=\;\Varid{su}\;\Varid{n}} -
we need to apply \ensuremath{\Varid{su}} to both sides.

This might seem minor: the particular proof here still came out very
concisely, but soon we will move onto trickier examples where this sort of
manual equational reasoning starts causing immense pain. 




















% So one way we an phrase this introduction is that smart case is part of some
% grand effort to replicate on-paper ETT convenience in ITT proof assistants.
% I think this is a justifiable perspective, but I'm not convinced I am the
% one to justify this... I don't use ETT.

% Another way is to focus right in on the critical part of ITT: transports
% and why these are painful. I think I like this more.

- Division in type theories: extensional/intensional
Much of the recent work in type theory has examined questions about many
properties of ETT can be replicated in ITT without breaking it's core
metatheoretic properties.
% TODO: Cite OTT, CTT etc...
Such attempts at bringing ideas from ETT into the intensional world can be
crudely categorised into two camps:
- Those that focus on extending what is propositionally provable, providing
a more expressive propositional equality.
- Those that examine how to replicate the convenience of equational reasoning
  in ETT.
This work is placed sole-y in the second camp, but focusses on an aspect.




Much of the recent work in type theory has explored the question: how



% \begin{figure}[tb]
% \centering
% \includegraphics[width = 0.4\hsize]{./figures/imperial}
% \caption{Imperial College Logo. It's nice blue, and the font is quite stylish. But you can choose a different one if you don't like it.}
% \label{fig:logo}
% \end{figure}

% Figure~\ref{fig:logo} is an example of a figure. 



% TYPESETTING TODO: We need to decide on standard formatting for variables,
% constructors, reducing functions
% This can actually resolve confusion such as in "f x" is "f" a defined symbol
% or variable?

\section{Main Contributions/Aims}

This interim

This interim report begins with a few example use-cases as motivation and a
review of related work. 

After this, I give the essentially single (so far) 
technical result: strong normalisation for STLC + rewrites into closed values.
This isn't really a new result (it is a small extension over termination for 
STLC + rewrites into closed booleans, which is described as having been shown
in the canonical Smart Case reference and also more-or-less a corollary 
of SN for STLC + boolean eta rules), but I am unawhere of a similar 
presentation which focusses on the
core changes to ordinary SN proofs (specifically around retaining monotonicity
of substitution) in the literature.

I then spend a considerable amount of time looking at how to extend these ideas
towards the aim of this project: a dependently-typed theory with rewrites into 
arbitrary first-order (ground) terms. Essentially, I focus on examples, building
intuition for where I have found the theory to be tricky and discussing the
options (as I currently see them) for how to proceed.
The discussion here is obviously not yet polished, but I hope it will be
a similarly exciting journey to read along as it was directly finding these
edge-cases.

Finally, I will end with some details surrounding implementation that I have 
investigated, specifically relating to efficient ground completion (revealing
a potential exciting additional avenue on the theory-side in the process!).






\section{A Larger Example: First-order Unification}



Inspired by \sidecite{sjoberg2015programming}, we present the use-case of
a verified first-order unification algorithm for a syntax containing variables, 
application and constants. The example is a bit involved, but we repeat it in
detail now for a few reasons:
\begin{itemize}
  \item Since the publication of this work, Agda has had a significant extension
  to it's automation of equational reasoning: global \ensuremath{\Conid{REWRITE}} rules
  \sidecite{cockx2020type}, so it will be
  interesting to examine where these can and cannot help.
  \item It's just a nice example: relatively self-contained while presenting a
  strong case for improved equational automation.
  \item The results of this project are all given in terms of a type-theoretic
  (approximately MLTT) metatheory. In fact, where possible, I aim to mechanise
  proofs in Agda. Implementing first-order unification for untyped terms should
  provide a nice introduction to how correct-by-construction programs/proofs are
  written, as well as the conventions used in this report.
\end{itemize}

Before we can implement anything however, we must define our syntax. 
We shall "index" terms by the number of variables in scope (the "context"). For 
example \ensuremath{\Conid{Tm}\;\Varid{3}} will represent a term with three different free variables 
available.

For this example we could easily restrict ourselves to a concrete
number, or even infinite, number of variables, but parameterising like this 
makes substitutions easier to define and lines up better with the syntaxes 
(containing binders) that we will look at later.

% ---------------------------------------------------------------------------- %
% First-order terms
% ---------------------------------------------------------------------------- %
\begin{definition}[First-Order Terms And Variables] \phantom{a} 

Variables and terms are defined inductively:
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{6}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[B]{}\Conid{Var}\;{}\<[6]%
\>[6]{}\mathbin{:}\;\Conid{ℕ}\;\Varid{→}\;\Keyword{Type}{}\<[E]%
\\
\>[B]{}\Conid{Tm}\;{}\<[6]%
\>[6]{}\mathbin{:}\;\Conid{ℕ}\;\Varid{→}\;\Keyword{Type}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
Terms themselves are easy. We have no binding constructs, so the context
stays the same in all cases:
% This remark applies to the definition of variables below but needs to be
% higher to avoid overlapping with later stuff.
\sideremark{This datatype is common in dependently-typed programming, and
is often named \ensuremath{\Conid{Fin}} for "finite set". One way to understand it is that
the indexing of \ensuremath{\Varid{vs}} ensures the context is incremented at least as many
times as the \ensuremath{\Conid{Var}} and \ensuremath{\Varid{vz}} requires one extra \ensuremath{\Varid{su}} call to make this inequality
strict. The flexibility enabling variables to exist in contexts
larger than themselves comes from the polymorphism of \ensuremath{\Varid{vz}} (\ensuremath{\Varid{vz}\;\mathbin{:}\;\Conid{Var}\;\Conid{Δ}} 
typechecks for any context \ensuremath{\Conid{Δ}\;\Varid{≥}\;\Varid{1}}).}
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{8}{@{}>{\hspre}l<{\hspost}@{}}%
\column{30}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\texttt{\textasciigrave}\anonymous \;{}\<[8]%
\>[8]{}\mathbin{:}\;\Conid{Var}\;\Conid{Γ}\;\Varid{→}\;\Conid{Tm}\;\Conid{Γ}{}\<[30]%
\>[30]{}\mbox{\onelinecomment  Variable}{}\<[E]%
\\
\>[3]{}\Varid{\char95 ·\char95 }\;{}\<[8]%
\>[8]{}\mathbin{:}\;\Conid{Tm}\;\Conid{Γ}\;\Varid{→}\;\Conid{Tm}\;\Conid{Γ}\;\Varid{→}\;\Conid{Tm}\;\Conid{Γ}{}\<[30]%
\>[30]{}\mbox{\onelinecomment  Application}{}\<[E]%
\\
\>[3]{}\Varid{⟨⟩}\;{}\<[8]%
\>[8]{}\mathbin{:}\;\Conid{Tm}\;\Conid{Γ}{}\<[30]%
\>[30]{}\mbox{\onelinecomment  Constant}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
Variables are determined uniquely by an index into the context, or in other 
words, can be represented by natural numbers strictly smaller than the number of 
variables in scope.
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{vz}\;\mathbin{:}\;\Conid{Var}\;(\Varid{su}\;\Conid{Γ}){}\<[E]%
\\
\>[3]{}\Varid{vs}\;\mathbin{:}\;\Conid{Var}\;\Conid{Γ}\;\Varid{→}\;\Conid{Var}\;(\Varid{su}\;\Conid{Γ}){}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{definition}
% ---------------------------------------------------------------------------- %

Unification can be defined as the task of finding a substitution (the "unifier") 
that maps the terms being unified to equal terms\remarknote{A reasonable
follow-up question here might be: what does equality on terms mean? For now,
given these are first-order terms we 
only consider on-the-nose syntactic equality.}. It seems reasonable then, to 
define substitutions next.

There are various different approaches to defining substitutions in proof
assistants. We shall use a first-order encoding of parallel substitutions; 
that is, a list of terms, equal in length to the
context, where operationally, the variable \ensuremath{\Varid{vz}} will be mapped to the first term
in the list  the list, \ensuremath{\Varid{vs}\;\Varid{vz}} to the second and so on... 
\sideremark{This encoding of
substitutions is nice for two reasons:\newline
1. Substitutions can be composed while staying canonical. i.e. unlike sequences
of single substitutions.\newline
2. Higher-order encodings of substitutions (i.e. as functions) don't scale to 
dependently-typed syntax (without "very-dependent types" \cite{hickey1996formal} 
\cite{altenkirch2023munchhausen})}



% ---------------------------------------------------------------------------- %
% Parallel substitutions
% ---------------------------------------------------------------------------- %
\begin{definition}{Parallel Substitions} \phantom{a}

We define substitutions in terms of lists of terms \ensuremath{\Conid{Tms}}, indexed first by the
context each of the terms in the list are in, and second by the length of the
list.
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[B]{}\Conid{Tms}\;\mathbin{:}\;\Conid{ℕ}\;\Varid{→}\;\Conid{ℕ}\;\Varid{→}\;\Keyword{Type}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{7}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{ε}\;{}\<[7]%
\>[7]{}\mathbin{:}\;\Conid{Tms}\;\Conid{Δ}\;\Varid{ze}{}\<[E]%
\\
\>[3]{}\Varid{\char95 ,\char95 }\;\mathbin{:}\;\Conid{Tms}\;\Conid{Δ}\;\Conid{Γ}\;\Varid{→}\;\Conid{Tm}\;\Conid{Δ}\;\Varid{→}\;\Conid{Tms}\;\Conid{Δ}\;(\Varid{su}\;\Conid{Γ}){}\<[E]%
\ColumnHook
\end{hscode}\resethooks

Interpreted as a substitution, \ensuremath{\Conid{Tms}\;\Conid{Δ}\;\Conid{Γ}} takes terms from context \ensuremath{\Conid{Γ}} to context
\ensuremath{\Conid{Δ}}.

\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{9}{@{}>{\hspre}l<{\hspost}@{}}%
\column{18}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[B]{}\Varid{lookup}\;{}\<[9]%
\>[9]{}\mathbin{:}\;\Conid{Var}\;\Conid{Γ}\;{}\<[18]%
\>[18]{}\Varid{→}\;\Conid{Tms}\;\Conid{Δ}\;\Conid{Γ}\;\Varid{→}\;\Conid{Tm}\;\Conid{Δ}{}\<[E]%
\\
\>[B]{}\Varid{\char95 [\char95 ]}\;{}\<[9]%
\>[9]{}\mathbin{:}\;\Conid{Tm}\;\Conid{Γ}\;{}\<[18]%
\>[18]{}\Varid{→}\;\Conid{Tms}\;\Conid{Δ}\;\Conid{Γ}\;\Varid{→}\;\Conid{Tm}\;\Conid{Δ}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks

Operationally, substitution is defined by recursion on the target term.

\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{10}{@{}>{\hspre}l<{\hspost}@{}}%
\column{16}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[B]{}\Varid{lookup}\;\Varid{vz}\;{}\<[16]%
\>[16]{}(\Varid{δ}\;\Varid{,}\;\Varid{u})\;\colonequiv\;\Varid{u}{}\<[E]%
\\
\>[B]{}\Varid{lookup}\;(\Varid{vs}\;\Varid{i})\;{}\<[16]%
\>[16]{}(\Varid{δ}\;\Varid{,}\;\Varid{u})\;\colonequiv\;\Varid{lookup}\;\Varid{i}\;\Varid{δ}{}\<[E]%
\\[\blanklineskip]%
\>[B]{}(\texttt{\textasciigrave}\;\Varid{i})\;{}\<[10]%
\>[10]{}[\mskip1.5mu \;\Varid{δ}\;\mskip1.5mu]\;\colonequiv\;\Varid{lookup}\;\Varid{i}\;\Varid{δ}{}\<[E]%
\\
\>[B]{}(\Varid{t}\;\Varid{·}\;\Varid{u})\;{}\<[10]%
\>[10]{}[\mskip1.5mu \;\Varid{δ}\;\mskip1.5mu]\;\colonequiv\;(\Varid{t}\;[\mskip1.5mu \;\Varid{δ}\;\mskip1.5mu])\;\Varid{·}\;(\Varid{u}\;[\mskip1.5mu \;\Varid{δ}\;\mskip1.5mu]){}\<[E]%
\\
\>[B]{}\Varid{⟨⟩}\;{}\<[10]%
\>[10]{}[\mskip1.5mu \;\Varid{δ}\;\mskip1.5mu]\;\colonequiv\;\Varid{⟨⟩}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{definition}
% ---------------------------------------------------------------------------- %

We can now define the goal of first-order unifiers (the goal of first-order
unification).

% ---------------------------------------------------------------------------- %
% First-order Unifiers
% ---------------------------------------------------------------------------- %
\begin{definition}[First-Order Unifiers] \phantom{a}
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[B]{}\Conid{Unifier}\;\mathbin{:}\;\Conid{Tm}\;\Conid{Γ}\;\Varid{→}\;\Conid{Tm}\;\Conid{Γ}\;\Varid{→}\;\Keyword{Type}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{success}\;\mathbin{:}\;(\Varid{δ}\;\mathbin{:}\;\Conid{Tms}\;\Conid{Γ}\;\Conid{Γ})\;\Varid{→}\;\Varid{t}\;[\mskip1.5mu \;\Varid{δ}\;\mskip1.5mu]\;=\;\Varid{u}\;[\mskip1.5mu \;\Varid{δ}\;\mskip1.5mu]\;\Varid{→}\;\Conid{Unifier}\;\Varid{t}\;\Varid{u}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{definition}
% ---------------------------------------------------------------------------- %

Unification can now be specified as a function that takes two terms and attempts
to find a unifier (using the standard \ensuremath{\Conid{Maybe}} type to deal possible failure):
\sideremark{Note that this is only a partial specification of unification. In a
perfect world, we would require evidence in the failure case that there really
is no unifier, but attempting this would add significant clutter to the
example.\newline
In fact, one could go even further: in the successful cases our specification
allows returning to any old unifier, of which there might be many. 
One could instead aim for the minimal/ most general unifier as in 
\cite{martelli1982efficient}, but, again, the machinery necessary to prove
a particular unifier is indeed the most general one is out of the scope of this 
example.}
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{unify}\;\mathbin{:}\;(\Varid{t}\;\Varid{u}\;\mathbin{:}\;\Conid{Tm}\;\Conid{Γ})\;\Varid{→}\;\Conid{Maybe}\;(\Conid{Unifier}\;\Varid{t}\;\Varid{u}){}\<[E]%
\ColumnHook
\end{hscode}\resethooks

We now attempy to define \ensuremath{\Varid{unify}} by cases:

\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{unify}\;\Varid{⟨⟩}\;\Varid{⟨⟩}\;\colonequiv\;\Varid{just}\;(\Varid{success}\;\Varid{?0}\;\Varid{refl}){}\<[E]%
\\
\>[3]{}\mbox{\onelinecomment  ?0 : Tms Γ Γ}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks

... and immediately hit a slight snag: \ensuremath{\Varid{⟨⟩}} is trivially equal to \ensuremath{\Varid{⟨⟩}} but we 
still need to provide a substitution. The identity substitution \ensuremath{\Varid{id}\;\mathbin{:}\;\Conid{Tms}\;\Conid{Γ}\;\Conid{Γ}} 
is probably most reasonable here, and can be constructed by recursion on context 
length (\ensuremath{\Varid{id}\;\mathbin{:}\;\Conid{Tms}\;(\Varid{su}\;\Conid{Γ})\;(\Varid{su}\;\Conid{Γ})} equals \ensuremath{\Varid{id}\;\mathbin{:}\;\Conid{Tms}\;\Conid{Γ}\;\Conid{Γ}} with all variables
incremented and \ensuremath{\texttt{\textasciigrave}\;\Varid{vz}} appended to the end).


\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{unify}\;\Varid{⟨⟩}\;\Varid{⟨⟩}\;\colonequiv\;\Varid{just}\;(\Varid{success}\;\Varid{id}\;\Varid{refl}){}\<[E]%
\ColumnHook
\end{hscode}\resethooks

We also have a couple easy failure cases:

\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{20}{@{}>{\hspre}l<{\hspost}@{}}%
\column{31}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{unify}\;(\Varid{t₁}\;\Varid{·}\;\Varid{t₂})\;{}\<[20]%
\>[20]{}\Varid{⟨⟩}\;{}\<[31]%
\>[31]{}\colonequiv\;\Varid{nothing}{}\<[E]%
\\
\>[3]{}\Varid{unify}\;\Varid{⟨⟩}\;{}\<[20]%
\>[20]{}(\Varid{u₁}\;\Varid{·}\;\Varid{u₂})\;{}\<[31]%
\>[31]{}\colonequiv\;\Varid{nothing}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks


A more interesting case crops up when \ensuremath{\Varid{t}} is a variable:

\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{unify}\;(\texttt{\textasciigrave}\;\Varid{i})\;\Varid{u}\;\colonequiv\;\Varid{?0}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks


Here, we need to perform an "occurs check" on \ensuremath{\Varid{u}}

\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{18}{@{}>{\hspre}l<{\hspost}@{}}%
\column{25}{@{}>{\hspre}l<{\hspost}@{}}%
\column{33}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{unify}\;(\texttt{\textasciigrave}\;\Varid{i})\;\Varid{u}\;\Keyword{with}\;\Varid{occurs?}\;\Varid{i}\;\Varid{u}{}\<[E]%
\\
\>[3]{}\Varid{unify}\;(\texttt{\textasciigrave}\;\Varid{i})\;\Varid{u}\;{}\<[18]%
\>[18]{}\mid \;\Varid{no}\;{}\<[25]%
\>[25]{}\Varid{p}\;{}\<[33]%
\>[33]{}\colonequiv\;\Varid{just}\;(\Varid{success}\;\{\mskip1.5mu \mathbin{!}\;\mathbin{!}\mskip1.5mu\}\;(\Varid{sym}\;\{\mskip1.5mu \mathbin{!}\;\mathbin{!}\mskip1.5mu\})){}\<[E]%
\\
\>[3]{}\Varid{unify}\;(\texttt{\textasciigrave}\;\Varid{i})\;\Varid{u}\;{}\<[18]%
\>[18]{}\mid \;\Varid{yes}\;{}\<[25]%
\>[25]{}\Varid{eq}\;{}\<[33]%
\>[33]{}\colonequiv\;\Varid{just}\;(\Varid{success}\;\Varid{id}\;\Varid{refl}){}\<[E]%
\\
\>[3]{}\Varid{unify}\;(\texttt{\textasciigrave}\;\Varid{i})\;\Varid{u}\;{}\<[18]%
\>[18]{}\mid \;\Varid{yes}\;{}\<[25]%
\>[25]{}(\Varid{l·}\;\anonymous )\;{}\<[33]%
\>[33]{}\colonequiv\;\Varid{nothing}{}\<[E]%
\\
\>[3]{}\Varid{unify}\;(\texttt{\textasciigrave}\;\Varid{i})\;\Varid{u}\;{}\<[18]%
\>[18]{}\mid \;\Varid{yes}\;{}\<[25]%
\>[25]{}(\Varid{·r}\;\anonymous )\;{}\<[33]%
\>[33]{}\colonequiv\;\Varid{nothing}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks








% So far (as of submitting this interim report) I have written a mechanised proof
% of strong normalisation of STLC + closed boolean rewrites. The main 
% contributions so far though comprise of the examples and edge-cases I have
% discovered in trying to extend these ideas towards dependent types.

% I have also started work on a proof-of-concept implementation of these ideas,
% currently comprising of a couple implementations of "ground completion" to deal
% with large sets of rewrites and an NbE evaluator for dependently-typed lambda 
% calculus, all written in Haskell.

% For next steps, my main priority is a normalisation/decidability of conversion
% proof for dependent types with some form of equational assumptions/
% local rewrites. The discussion in section ? attempts to summarise the 
% possibilities here.

% Decidability of conversion is important (critical for decidability of 
% typechecking) but it is not the be-all and end-all of the metatheoretical 
% results. I expect soundness to be relatively easy given the equational 
% pre-conditions on rewrites can exactly correspond to the relaxed conversion.
% Subject reduction is also free given our reduction rules are typed. Confluence
% is a bit more subtle but should follow easily from a proof that rewriting to 
% completion results in a confluent set of rewrites.

% On the implementation side, my main aim is a proof-of-concept typechecker with
% a few built-in type formers (...). I am interested in doing some small 
% explorations into performance: specifically comparing rewriting to completion
% and e-graphs (I have already implemented basic versions of both, but for
% proper performance testing, I should spend some time optimising and I need to
% find something to compare against). 

% Depending on how successful the metatheory work goes (i.e. if I finish early, or
% quickly hit major roadblocks) I might also look into implementation in a fork of
% the Agda proof assistent. Agda is a very large codebase, but my hope is that 
% many  existing features (such as its global REWRITE RULES) have already laid 
% much of the groundwork.


\section{One More Example: Instrinsically-typed System F}

The prior section gave an example where automating congruence simplifies
equational reasoning. Cases like this admittedly still might not be fully
convincing though: couldn't we just create a small automation script (a 
"tactic") to automatically generate such proofs?

The real pain of not being able to reflect propositional equality proofs into
definitional assumptions starts to rear it's head when one works with
heavily-indexed types. The general pattern is that as follows:
\begin{itemize}
  \item some operations on an indexed
  type \ensuremath{\Conid{A}\;\mathbin{:}\;\Conid{I}\;\Varid{→}\;\Keyword{Type}} are forced to explicitly coerce ("transport") along
  propositional equations relating different index expression.
  \item One now attempts to prove equations about these indexed types, and has
  to deal with explicitly shifting transports around.
\end{itemize}

\setchapterpreamble[u]{\margintoc}

\chapter{Background and Related Work}
\labch{background}

\section{Dependent Pattern Matching and LHS Unification}

Proof assistents like Agda that feature both metavariables and dependent pattern
matching benefit from using two different unification algorithms 
\sidecite{norell2007towards}: One often referred to as "RHS unification" 
designed to solve metavariables and the other "LHS unification" to deal with
pattern-matching.

The motivation for this distinction is that the desired properties of each
unification procedure are different. RHS unification is allowed to fill
metavariables whenever they are unique up to definitional equality, meaning
e.g. neutral equations like \ensuremath{\Varid{f}\;\Varid{x}\;\colonequiv\;\Varid{f}\;\Varid{?0}} can be solved with \ensuremath{\Varid{?0}\;\colonequiv\;\Varid{x}}.

LHS unification needs to be more careful.

In fact RHS unification can be even bolder: e.g. lossily solving 
\ensuremath{\Varid{pred}\;\Varid{x}\;\colonequiv\;\Varid{pred}\;\Varid{?0}} with \ensuremath{\Varid{?0}\;\colonequiv\;\Varid{x}}

Agda's approach the LHS unification then is to ...

\subsection{Green Slime}

....



\section{Equality in Type Theory}



% I think we need to move some of the conversion stuff to here because the
% immediately below sections really rely on it...


To further motivate

\section{Smart Case}

This work was primarily inspired by a presentation 
\sidecite{altenkirch2011case}. The hope is that 
recent advances in the meta-theory of type theory (i.e. a renewed interest in 
semantic approaches to normalisation)

This work focusses on a type theory with ground "equational assumptions".

\section{η and Extensionality}

Extensionality has a very concrete definition in dependent type theories


Note that even in ETT with equality reflection, conversion is not necessarily
complete with respect to semantic/observational equality from the point of view
of the meta. i.e. type theories which allow for
quantification over a sort of types, \ensuremath{\Keyword{Type}}, but prevent case splitting
on this universe obey "for free" parametricity theorems, but building a type
theory where these parametericity results are internally provable is very 
involved \sidecite{altenkirch2024internal}.

When restricting ourselves to discussion of specific types (and functions taking
arguments of those types) though, we do find that many of these disparate
notions start to coincide.

% Formal proof that observational equality of functions on booleans is provable
% from η
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[B]{}\mbox{\onelinecomment  We assume f true = f true, f false = g false}{}\<[E]%
\\[\blanklineskip]%
\>[B]{}\mbox{\onelinecomment  f}{}\<[E]%
\\
\>[B]{}\mbox{\onelinecomment  ≡ λ b → f b}{}\<[E]%
\\
\>[B]{}\mbox{\onelinecomment  ≡ λ b → f (if b then True else False)}{}\<[E]%
\\
\>[B]{}\mbox{\onelinecomment  ≡ λ b → if b then f True else f False}{}\<[E]%
\\
\>[B]{}\mbox{\onelinecomment  ≡ λ b → if b then g True else g False}{}\<[E]%
\\
\>[B]{}\mbox{\onelinecomment  ≡ λ b → g (if b then True else False)}{}\<[E]%
\\
\>[B]{}\mbox{\onelinecomment  ≡ λ b → g b}{}\<[E]%
\\
\>[B]{}\mbox{\onelinecomment  ≡ g}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks



One could view much of the recent progress in type theory as taking bits and
pieces from ETT and carefully adding them to ITT in such a way as to avoid
breaking the core meta-theoretical properties. Of course, not everything
falls under this umbrella: in fact arguably the most famous modern type theory
result (univalence) explores a principle which is fundemantally incompatible
with erasing transports, but even this law can  be viewed as a kind of 
extensionality rule for types.


This work focusses less on the expressivity side (in fact, the ultimate aim is
to elaborate Smart Case into a small core without it)


\section{Decidability of Conversion}

% Formal definition of conversion
A conversion relation is a congruence relation on terms that aims to capture
a practical (i.e. decidable) subset of semantic equality. 
Applied to simple type systems, conversion
acts as a nice declarative specification of what reduction/normalisation
should achieve (normal forms should enable easy checking of conversion). In
the context of dependent types, conversion is central to the type system,
specifying exactly the definitional equality. For this reason, decidability
of typechecking in the context of dependent types hinges on decidability
of conversion. e.g. consider the typing rule for function application
\ensuremath{\Varid{\char95 ·\char95 }\;\mathbin{:}\;\Conid{Tm}\;\Conid{Γ}\;(\Conid{A}\;\Varid{⇒}\;\Conid{B})\;\Varid{→}\;\Conid{Tm}\;\Conid{Γ}\;\Conid{A}\;\Varid{→}\;\Conid{Tm}\;\Conid{Γ}\;\Conid{B}} in STLC. The repetition of \ensuremath{\Conid{A}} here
in STLC can simply refer to on-the-nose syntactic equality, given equality
(conversion) on types in STLC is trivial. In the setting of dependent types,
terms can appear within types, and so to typecheck application while respecting
conversion, we must decide whether said embedded terms are convertible.

Conversion typically includes syntactic equality extended with specific
computation (i.e. β/η) laws. However, this is not the only
design possibility: forgoing computation rules enables extending definitional
equality with arbitrary equational assumptions 
\sidecite{sjoberg2015programming}. Weak type theories forgo non-trivial 
conversion entirely \sidecite{winterhalter2020formalisation}.
On the other hand, extensional type theories admit arbitrary equality 
reflection.

% ---------------------------------------------------------------------------- %
% Formal definition of equality reflection
% ---------------------------------------------------------------------------- %

Equality reflection expresses that the object-theory judgement of a
propositional equality can be turned into a meta-theory judgement of
convertibility between the two terms.
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{5}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[5]{}\Varid{reflect}\;\mathbin{:}\;\Conid{Tm}\;\Conid{Γ}\;(\Varid{t}\;\Varid{≡'}\;\Varid{u})\;\Varid{→}\;\Varid{t}\;\mathord{\sim}\;\Varid{u}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
% ---------------------------------------------------------------------------- %

conversion checking in this setting is completely undecidable (it requires
arbitrary proof search to find possible \ensuremath{\Varid{t}\;\Varid{≡'}\;\Varid{u}} terms).

This project focusses on type theories with decidable conversion, but one
could view the overarching mission statement here as investigating how close we 
can get to the convenience of on-paper ETT without losing decidability. 

\subsection{Reduction-based}

% ---------------------------------------------------------------------------- %
% Formal definition of strong normalisation
% ---------------------------------------------------------------------------- %
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Conid{SN}\;\colonequiv\;\Pi\;\Varid{t}\;\Varid{→}\;\Conid{Acc}\;\Varid{\char95 →β\char95 }\;\Varid{t}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
Where \ensuremath{\Conid{Acc}} is the accessibility predicate and \ensuremath{\Varid{\char95 →β\char95 }} is the small-step 
reduction relation (congruence of all \ensuremath{\Varid{β}} rules)

Clasically: there exists no infinite chain of reductions
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{5}{@{}>{\hspre}l<{\hspost}@{}}%
\column{7}{@{}>{\hspre}l<{\hspost}@{}}%
\column{12}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Keyword{record}\;\Varid{∞Chain}\;(\Varid{r}\;\mathbin{:}\;\Conid{A}\;\Varid{→}\;\Conid{A}\;\Varid{→}\;\Keyword{Type})\;(\Varid{x}\;\mathbin{:}\;\Conid{A})\;\mathbin{:}\;\Keyword{Type}\;\Keyword{where}{}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\Keyword{coinductive}{}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\Keyword{field}{}\<[E]%
\\
\>[5]{}\hsindent{2}{}\<[7]%
\>[7]{}\{\mskip1.5mu \Varid{y}\mskip1.5mu\}\;{}\<[12]%
\>[12]{}\mathbin{:}\;\Conid{A}{}\<[E]%
\\
\>[5]{}\hsindent{2}{}\<[7]%
\>[7]{}\Varid{head}\;\mathbin{:}\;\Varid{r}\;\Varid{x}\;\Varid{y}{}\<[E]%
\\
\>[5]{}\hsindent{2}{}\<[7]%
\>[7]{}\Varid{tail}\;\mathbin{:}\;\Varid{∞Chain}\;\Varid{r}\;\Varid{y}{}\<[E]%
\\[\blanklineskip]%
\>[3]{}\Conid{SN-classical}\;\colonequiv\;\Pi\;\Varid{t}\;\Varid{→}\;\Varid{¬}\;\Varid{∞Chain}\;\Varid{\char95 →β\char95 }\;\Varid{t}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
Under Markov's principle, these two concepts coincide
% Proof?
% ---------------------------------------------------------------------------- %

Some type theories lack obvious strongly normalising operational semantics but 
still have decidable conversion (e.g. type theories with eta-equality
or explicit substitutions \sidecite{altenkirch2009big}). 
One alternative strategy is to derive an
algorithm to decide conversion from weak-head normalisation 
\sidecite{abel2016decidability}. One extra nice advantage of such an approach is
that confluence of the reduction relation is usually much easier to show, with
often only one small-step possible from each syntactic construct. The downside
is that weak-head normalisation alone does not imply decidability of conversion 
e.g. in a system with η-equality of functions, arbitrary function-typed terms 
can be soundly expanded like `f → λ x. f x` to trivially end up in WHNF, but 
clearly a procedure which cycles between η-expanding and recursing on the bodies
to decide equality of functions will never terminate. Some care is required to
work out what laws should be dealt with by reduction and which can be checked
during conversion checking, as well as justifying this cyclic algorithm
does indeed terminate.


% Formal definition of weak-head reduction
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[B]{}\mbox{\onelinecomment  To characterise weak-head normal forms, we need to introduce the concept of}{}\<[E]%
\\
\>[B]{}\mbox{\onelinecomment  introduction and elimination forms. We consider types inductively defined}{}\<[E]%
\\
\>[B]{}\mbox{\onelinecomment  by their introduction forms, while elimination forms express }{}\<[E]%
\\
\>[B]{}\mbox{\onelinecomment  recursion/induction over these structures.}{}\<[E]%
\\
\>[B]{}\mbox{\onelinecomment  I think this division is most cleanly expressed via β rules. All β rules}{}\<[E]%
\\
\>[B]{}\mbox{\onelinecomment  are of the form `e (i t₁ ... tₙ) u₁ ... uₙ → v`, where `e` is an elimination}{}\<[E]%
\\
\>[B]{}\mbox{\onelinecomment  constant and i is an introduction one.}{}\<[E]%
\\[\blanklineskip]%
\>[B]{}\mbox{\onelinecomment  Weak-head normal forms can then be defined as either headed by some}{}\<[E]%
\\
\>[B]{}\mbox{\onelinecomment  introduction rule, or a spine of elimination forms blocked on a variable}{}\<[E]%
\\
\>[B]{}\mbox{\onelinecomment  Whnf t = intro-headed t ⊎ neutral t}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks


Big-step normalisation has also been demonstrated to extend to
dependent types \sidecite{altenkirch2020big}.


Much of the original work on "Smart Case" attacked the problem using big step
reduction (\sidecite{altenkirch2009smart}, private 
communication with Thorsten Altenkirch). Looking up a neutral expression
in a set of constraints is not too tricky, but problems seem to occur when
merging constraint sets (the main necessary case is adding one new constraint
to a set). For deciding equality of the neutrals when looking them, all neutral
LHSs must be kept normalised with respect to all other constraints. Adding a
single new constraint might unblock multiple neutral LHSs of other constraints,
which might unblock yet more etc... so the only applicable technique to arrive
at a fully normalised constraint set is to iterate reducing all constraints
with respect to others until a fixed point (i.e. very similar to ground 
completion). The only technique I am aware of to show such a fixed point exists
is to demonstrate that there exists some well-founded ordering on constraint
sets that continues to decrease during the repairing process: in other words
we end up needing a small step reduction relation anyway.


\subsection{Reduction-free Normalisation}

Normalisation-by-evaluation really comes into it's own when working with a
syntax quotiented by conversion.

Another 


\setchapterpreamble[u]{\margintoc}

\chapter{Simply Typed Lambda Calculus with Closed Boolean Rewrites}
\labch{simply}

\section{Syntax}

Before we begin to prove anything, we must define an object theory.
Unlike many traditional approaches to meta-theory, inspired by so-called 
"semantic" \remarknote{also called "algebraic", "reduction-free"} 
approaches, we consider only well-typed terms. 
However we don't yet go so far as to quotient our syntax by conversion,
so e.g. \ensuremath{(\Varid{λ}\;\Varid{x}\;\Varid{→}\;\Varid{x})\;\Varid{y}} and \ensuremath{\Varid{y}} will remain distinguishable.

Our base syntax looks like:

% ---------------------------------------------------------------------------- %
% Core STLC Definition
% ---------------------------------------------------------------------------- %
% We really should use multiple columns here
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{5}{@{}>{\hspre}l<{\hspost}@{}}%
\column{10}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[B]{}\mbox{\onelinecomment  Todo: Hide the 'data' keyword here}{}\<[E]%
\\
\>[B]{}\Keyword{data}\;\Conid{Ctx}\;\mathbin{:}\;\Keyword{Type}{}\<[E]%
\\
\>[B]{}\Keyword{data}\;\Conid{Ty}\;{}\<[10]%
\>[10]{}\mathbin{:}\;\Keyword{Type}{}\<[E]%
\\
\>[B]{}\Conid{Var}\;\mathbin{:}\;\Conid{Ctx}\;\Varid{→}\;\Conid{Ty}\;\Varid{→}\;\Keyword{Type}{}\<[E]%
\\
\>[B]{}\Conid{Tm}\;{}\<[5]%
\>[5]{}\mathbin{:}\;\Conid{Ctx}\;\Varid{→}\;\Conid{Ty}\;\Varid{→}\;\Keyword{Type}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{7}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{ε}\;{}\<[7]%
\>[7]{}\mathbin{:}\;\Conid{Ctx}{}\<[E]%
\\
\>[3]{}\Varid{\char95 ,\char95 }\;\mathbin{:}\;\Conid{Ctx}\;\Varid{→}\;\Conid{Ty}\;\Varid{→}\;\Conid{Ctx}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{\char95 ⇒\char95 }\;\mathbin{:}\;\Conid{Ty}\;\Varid{→}\;\Conid{Ty}\;\Varid{→}\;\Conid{Ty}{}\<[E]%
\\
\>[3]{}\Conid{𝔹'}\;\mathbin{:}\;\Conid{Ty}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks

\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{10}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{vz}\;{}\<[10]%
\>[10]{}\mathbin{:}\;\Conid{Var}\;(\Conid{Γ}\;\Varid{,}\;\Conid{A})\;\Conid{A}{}\<[E]%
\\
\>[3]{}\Varid{vs}\;{}\<[10]%
\>[10]{}\mathbin{:}\;\Conid{Var}\;\Conid{Γ}\;\Conid{B}\;\Varid{→}\;\Conid{Var}\;(\Conid{Γ}\;\Varid{,}\;\Conid{A})\;\Conid{B}{}\<[E]%
\\[\blanklineskip]%
\>[3]{}\texttt{\textasciigrave}\anonymous \;{}\<[10]%
\>[10]{}\mathbin{:}\;\Conid{Var}\;\Conid{Γ}\;\Conid{A}\;\Varid{→}\;\Conid{Tm}\;\Conid{Γ}\;\Conid{A}{}\<[E]%
\\
\>[3]{}\Varid{\char95 ·\char95 }\;{}\<[10]%
\>[10]{}\mathbin{:}\;\Conid{Tm}\;\Conid{Γ}\;(\Conid{A}\;\Varid{⇒}\;\Conid{B})\;\Varid{→}\;\Conid{Tm}\;\Conid{Γ}\;\Conid{A}\;\Varid{→}\;\Conid{Tm}\;\Conid{Γ}\;\Conid{B}{}\<[E]%
\\
\>[3]{}\Varid{λ}\anonymous \;{}\<[10]%
\>[10]{}\mathbin{:}\;\Conid{Tm}\;(\Conid{Γ}\;\Varid{,}\;\Conid{A})\;\Conid{B}\;\Varid{→}\;\Conid{Tm}\;\Conid{Γ}\;(\Conid{A}\;\Varid{⇒}\;\Conid{B}){}\<[E]%
\\[\blanklineskip]%
\>[3]{}\Varid{true}\;{}\<[10]%
\>[10]{}\mathbin{:}\;\Conid{Tm}\;\Conid{Γ}\;\Conid{𝔹'}{}\<[E]%
\\
\>[3]{}\Varid{false}\;{}\<[10]%
\>[10]{}\mathbin{:}\;\Conid{Tm}\;\Conid{Γ}\;\Conid{𝔹'}{}\<[E]%
\\
\>[3]{}\Conid{𝔹-rec}\;{}\<[10]%
\>[10]{}\mathbin{:}\;\Conid{Tm}\;\Conid{Γ}\;\Conid{𝔹'}\;\Varid{→}\;\Conid{Tm}\;\Conid{Γ}\;\Conid{A}\;\Varid{→}\;\Conid{Tm}\;\Conid{Γ}\;\Conid{A}\;\Varid{→}\;\Conid{Tm}\;\Conid{Γ}\;\Conid{A}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks

% ---------------------------------------------------------------------------- %



% ---------------------------------------------------------------------------- %
% Note on the type signatures of non-⇒ constants
% ---------------------------------------------------------------------------- %
After lambda abstraction and application has been defined, we have quite 
a bit of flexibility when defining other constants.

For example, constants of arity >0 can have their premises/conclusions
separated by external (meta-level) or internal (object-level) function
types. E.g. natural number successor can be defined as
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[B]{}\Conid{ℕ'}\;\mathbin{:}\;\Conid{Ty}{}\<[E]%
\\[\blanklineskip]%
\>[B]{}\Varid{suⁱ}\;\mathbin{:}\;\Conid{Tm}\;\Conid{Γ}\;(\Conid{ℕ'}\;\Varid{⇒}\;\Conid{ℕ'}){}\<[E]%
\ColumnHook
\end{hscode}\resethooks
or
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[B]{}\Varid{suᵉ}\;\mathbin{:}\;\Conid{Tm}\;\Conid{Γ}\;\Conid{ℕ'}\;\Varid{→}\;\Conid{Tm}\;\Conid{Γ}\;\Conid{ℕ'}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
Either can be defined in terms of the other
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[B]{}\Varid{suⁱ}\;\colonequiv\;\Varid{λ}\;(\Varid{suᵉ}\;(\texttt{\textasciigrave}\;\Varid{vz})){}\<[E]%
\\
\>[B]{}\Varid{suᵉ}\;\Varid{n}\;\colonequiv\;\Varid{suⁱ}\;\Varid{·}\;\Varid{n}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
A third option is to ask for the premises to exist in the appropriate place
in the context
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[B]{}\Varid{su,}\;\mathbin{:}\;\Conid{Tm}\;(\Conid{Γ}\;\Varid{,}\;\Conid{ℕ'})\;\Conid{ℕ'}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
Which is equivalent to the suⁱ definition by \ensuremath{\Varid{λ}}/\ensuremath{\Varid{λ}\Varid{⁻¹}} 
% TODO: define ƛ⁻¹ somewhere
This last definition avoids any reference to meta or object-level functions
and so in a way places the least constraints on the surrounding type
theories. My impression is that this is why such a style is popular
in e.g. the nLab wiki \sidecite{nlab2024product}. However, this approach has 
dire consequences with respect to computation (specifically, stability of 
typing under substitution).
e.g. it is not possible to apply \ensuremath{\Varid{su,}} applied to \ensuremath{\Varid{ze}\;\mathbin{:}\;\Conid{Tm}\;\Conid{Γ}\;\Conid{ℕ}} directly;
instead, forming a β-redex is actually required: \ensuremath{(\Varid{λ}\;\Varid{su,})\;\Varid{·}\;\Varid{ze}}.

In this work, I stick to the convention of using meta-level functions
to distinguish premises due to the notational convenience of meta-level 
application.

The same flexibility arises again, one level deeper, when considering
constants that act like binders (typically elimination forms).
For example, the recursion principle for sum types can be seemingly
alternatively expressed as

\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[B]{}\Varid{+-recⁱ}\;\mathbin{:}\;\Conid{Tm}\;\Conid{Γ}\;(\Conid{A}\;\Varid{⇒}\;\Conid{C})\;\Varid{→}\;\Conid{Tm}\;\Conid{Γ}\;(\Conid{B}\;\Varid{⇒}\;\Conid{C})\;\Varid{→}\;\Conid{Tm}\;\Conid{Γ}\;(\Conid{A}\;\Varid{+'}\;\Conid{B})\;\Varid{→}\;\Conid{Tm}\;\Conid{Γ}\;\Conid{C}{}\<[E]%
\\
\>[B]{}\Varid{+-recᵉ}\;\mathbin{:}\;(\Conid{Tm}\;\Conid{Γ}\;\Conid{A}\;\Varid{→}\;\Conid{Tm}\;\Conid{Γ}\;\Conid{C})\;\Varid{→}\;(\Conid{Tm}\;\Conid{Γ}\;\Conid{B}\;\Varid{→}\;\Conid{Tm}\;\Conid{Γ}\;\Conid{C})\;\Varid{→}\;\Conid{Tm}\;\Conid{Γ}\;(\Conid{A}\;\Varid{+'}\;\Conid{B})\;\Varid{→}\;\Conid{Tm}\;\Conid{Γ}\;\Conid{C}{}\<[E]%
\\
\>[B]{}\Varid{+-rec,}\;\mathbin{:}\;\Conid{Tm}\;(\Conid{Γ}\;\Varid{,}\;\Conid{A})\;\Conid{C}\;\Varid{→}\;\Conid{Tm}\;(\Conid{Γ}\;\Varid{,}\;\Conid{B})\;\Conid{C}\;\Varid{→}\;\Conid{Tm}\;\Conid{Γ}\;(\Conid{A}\;\Varid{+'}\;\Conid{B})\;\Varid{→}\;\Conid{Tm}\;\Conid{Γ}\;\Conid{C}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
Definitions like \ensuremath{\Varid{+-recᵉ}} are not allowed in our meta-theory so we can discard 
this option immediately.
\remarknote{Specifically, this fails the "strict positivity" condition of 
inductive definitions. This sort of definition effectively simulates HOAS 
\cite{pfenning1988higher}, but in traditional ITT meta-theory, the 
meta-function space is too powerful - e.g. functions can
go beyond binding and perform real computation, such as pattern matching, 
which allows so-called "exotic terms".}

A possible motivation for \ensuremath{\Varid{+-recⁱ}} is that following this convention ensures
that there is only one actual binding construct in the type theory (\ensuremath{\Varid{λ}}), which
can end up slightly simplifying the definition of substitution. On the other
hand, I find \ensuremath{\Varid{+-rec,}} more convenient (in practice, I find it is very common to
want to immediately bind the newly-available variables in each case), so I will
stick to this convention.
% ---------------------------------------------------------------------------- %

\section{Substitutions}

\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{5}{@{}>{\hspre}l<{\hspost}@{}}%
\column{6}{@{}>{\hspre}l<{\hspost}@{}}%
\column{8}{@{}>{\hspre}l<{\hspost}@{}}%
\column{9}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[B]{}\Keyword{data}\;\Conid{Tms[\char95 ]}\;(\Varid{q}\;\mathbin{:}\;\Conid{Sort})\;\mathbin{:}\;\Conid{Ctx}\;\Varid{→}\;\Conid{Ctx}\;\Varid{→}\;\Keyword{Type}\;\Keyword{where}{}\<[E]%
\\
\>[B]{}\hsindent{5}{}\<[5]%
\>[5]{}\Varid{ε}\;{}\<[9]%
\>[9]{}\mathbin{:}\;\Conid{Tms[}\;\Varid{q}\;\mskip1.5mu]\;\Conid{Δ}\;\Varid{ε}{}\<[E]%
\\
\>[B]{}\hsindent{5}{}\<[5]%
\>[5]{}\Varid{\char95 ,\char95 }\;\mathbin{:}\;\Conid{Tms[}\;\Varid{q}\;\mskip1.5mu]\;\Conid{Δ}\;\Conid{Γ}\;\Varid{→}\;\Conid{Tm[}\;\Varid{q}\;\mskip1.5mu]\;\Conid{Δ}\;\Conid{A}\;\Varid{→}\;\Conid{Tms[}\;\Varid{q}\;\mskip1.5mu]\;\Conid{Δ}\;(\Conid{Γ}\;\Varid{,}\;\Conid{A}){}\<[E]%
\\[\blanklineskip]%
\>[B]{}\Keyword{variable}{}\<[E]%
\\
\>[B]{}\hsindent{3}{}\<[3]%
\>[3]{}\Varid{δ}\;\Varid{σ}\;\Varid{ξ}\;\Varid{δ₁}\;\Varid{δ₂}\;\Varid{δ₃}\;\Varid{σ₁}\;\Varid{σ₂}\;\Varid{σ₃}\;\Varid{ξ₁}\;\Varid{ξ₂}\;\Varid{ξ₃}\;\mathbin{:}\;\Conid{Tms[}\;\Varid{q}\;\mskip1.5mu]\;\Conid{Δ}\;\Conid{Γ}{}\<[E]%
\\[\blanklineskip]%
\>[B]{}\Conid{Vars}\;\colonequiv\;\Conid{Tms[}\;\Conid{V}\;\mskip1.5mu]{}\<[E]%
\\
\>[B]{}\Conid{Tms}\;{}\<[6]%
\>[6]{}\colonequiv\;\Conid{Tms[}\;\Conid{T}\;\mskip1.5mu]{}\<[E]%
\\[\blanklineskip]%
\>[B]{}\Varid{vz[\char95 ]}\;\mathbin{:}\;\Pi\;\Varid{q}\;\Varid{→}\;\Conid{Tm[}\;\Varid{q}\;\mskip1.5mu]\;(\Conid{Γ}\;\Varid{,}\;\Conid{A})\;\Conid{A}{}\<[E]%
\\
\>[B]{}\Varid{vz[}\;\Conid{V}\;\mskip1.5mu]\;\colonequiv\;\Varid{vz}{}\<[E]%
\\
\>[B]{}\Varid{vz[}\;\Conid{T}\;\mskip1.5mu]\;\colonequiv\;\texttt{\textasciigrave}\;\Varid{vz}{}\<[E]%
\\[\blanklineskip]%
\>[B]{}\Varid{suc[\char95 ]}\;\mathbin{:}\;\Pi\;\Varid{q}\;\Varid{→}\;\Conid{Tm[}\;\Varid{q}\;\mskip1.5mu]\;\Conid{Γ}\;\Conid{B}\;\Varid{→}\;\Conid{Tm[}\;\Varid{q}\;\mskip1.5mu]\;(\Conid{Γ}\;\Varid{,}\;\Conid{A})\;\Conid{B}{}\<[E]%
\\
\>[B]{}\Varid{\char95 ⁺\char95 }\;{}\<[8]%
\>[8]{}\mathbin{:}\;\Conid{Tms[}\;\Varid{q}\;\mskip1.5mu]\;\Conid{Δ}\;\Conid{Γ}\;\Varid{→}\;\Pi\;\Conid{A}\;\Varid{→}\;\Conid{Tms[}\;\Varid{q}\;\mskip1.5mu]\;(\Conid{Δ}\;\Varid{,}\;\Conid{A})\;\Conid{Γ}{}\<[E]%
\\
\>[B]{}\Varid{\char95 \char94 \char95 }\;{}\<[8]%
\>[8]{}\mathbin{:}\;\Conid{Tms[}\;\Varid{q}\;\mskip1.5mu]\;\Conid{Δ}\;\Conid{Γ}\;\Varid{→}\;\Pi\;\Conid{A}\;\Varid{→}\;\Conid{Tms[}\;\Varid{q}\;\mskip1.5mu]\;(\Conid{Δ}\;\Varid{,}\;\Conid{A})\;(\Conid{Γ}\;\Varid{,}\;\Conid{A}){}\<[E]%
\\
\>[B]{}\Varid{\char95 [\char95 ]}\;{}\<[8]%
\>[8]{}\mathbin{:}\;\Conid{Tm[}\;\Varid{q}\;\mskip1.5mu]\;\Conid{Γ}\;\Conid{A}\;\Varid{→}\;\Conid{Tms[}\;\Varid{s}\;\mskip1.5mu]\;\Conid{Δ}\;\Conid{Γ}\;\Varid{→}\;\Conid{Tm[}\;\Varid{q}\;\Varid{⊔}\;\Varid{s}\;\mskip1.5mu]\;\Conid{Δ}\;\Conid{A}{}\<[E]%
\\
\>[B]{}\Varid{id}\;\mathbin{:}\;\Conid{Vars}\;\Conid{Γ}\;\Conid{Γ}{}\<[E]%
\\[\blanklineskip]%
\>[B]{}\Varid{<\char95 >}\;\mathbin{:}\;\Conid{Tm}\;\Conid{Γ}\;\Conid{A}\;\Varid{→}\;\Conid{Tms[}\;\Conid{T}\;\mskip1.5mu]\;\Conid{Γ}\;(\Conid{Γ}\;\Varid{,}\;\Conid{A}){}\<[E]%
\ColumnHook
\end{hscode}\resethooks

\subsection{Equations}

The following equations are easily proved by induction on terms/lists of 
terms/contexts (see \sidecite{altenkirch2024copypaste} for the details). 
We will generally use these equations where necessary implicitly, as if we are
in an extensional metatheory. In fact, in the mechanisation, these equations
are turned into Agda REWRITE rules to avoid cluttering proofs with transports.

\section{Conversion}

\section{Normalisation}

We consider a type theory with functions, booleans
% TODO: Maybe extend with more tycons
and coproducts and aim to prove normalisation

\subsection{Spontaneous Reductions}

Inspired by Dougherty and Subrahmanyam's approach to proving strong 
normalisation of STLC plus equational assumptions targeting coproduct values
\sidecite{dougherty2000equality}, we define a
reduction-relation that over-approximates reduction relation. Their work
targets coprodudcts, which makes their relation much more fiddly. e.g. there
reduction relation does not necessarily preserve types, and there is a
complex interplay between variables and constants. I believe the latter is
primarily motivated by a specific monotonicity (w.r.t. reduction) of
substitution condition required during the normalisation argument, which I will 
further elaborate on later, and becomes much easier to deal with when 
%TODO Link to where we end up covering this
restricting the targets of rewrites to closed terms.

% Formal definition of spontaneous reduction
% ---------------------------------------------------------------------------- %
Spontaneous Reduction


\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[B]{}\Varid{t/f}\;\mathbin{:}\;\Conid{Tm}\;\Conid{Γ}\;\Conid{A}\;\Varid{→}\;\Keyword{Type}{}\<[E]%
\\[\blanklineskip]%
\>[B]{}\Keyword{data}\;\Varid{\char95 ⟶!\char95 }\;\mathbin{:}\;\Conid{Tm}\;\Conid{Γ}\;\Conid{A}\;\Varid{→}\;\Conid{Tm}\;\Conid{Γ}\;\Conid{A}\;\Varid{→}\;\Keyword{Type}\;\Keyword{where}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks

Standard beta reductions
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{13}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{β}\;{}\<[13]%
\>[13]{}\mathbin{:}\;\Pi\;\{\mskip1.5mu \Varid{ƛt}\;\Varid{t[u]}\mskip1.5mu\}\;\Varid{→}\;\Varid{ƛt}\;=\;\Varid{λ}\;\Varid{t}\;\Varid{→}\;\Varid{t[u]}\;=\;\Varid{t}\;[\mskip1.5mu \;\Varid{<}\;\Varid{u}\;\Varid{>}\;\mskip1.5mu]\;\Varid{→}\;(\Varid{ƛt}\;\Varid{·}\;\Varid{u})\;\Varid{⟶!}\;\Varid{t[u]}{}\<[E]%
\\
\>[3]{}\Varid{rec-true}\;{}\<[13]%
\>[13]{}\mathbin{:}\;\Conid{𝔹-rec}\;\Varid{true}\;\Varid{u}\;\Varid{v}\;\Varid{⟶!}\;\Varid{u}{}\<[E]%
\\
\>[3]{}\Varid{rec-false}\;\mathbin{:}\;\Conid{𝔹-rec}\;\Varid{false}\;\Varid{u}\;\Varid{v}\;\Varid{⟶!}\;\Varid{v}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks

Spontaneous reduction
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{13}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{rw}\;{}\<[13]%
\>[13]{}\mathbin{:}\;\Varid{¬}\;\Varid{t/f}\;\{\mskip1.5mu \Conid{A}\;\colonequiv\;\Conid{𝔹'}\mskip1.5mu\}\;\Varid{t}\;\Varid{→}\;\Varid{t/f}\;\{\mskip1.5mu \Conid{A}\;\colonequiv\;\Conid{𝔹'}\mskip1.5mu\}\;\Varid{u}\;\Varid{→}\;\Varid{t}\;\Varid{⟶!}\;\Varid{u}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks

Congruence rules

\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{10}{@{}>{\hspre}l<{\hspost}@{}}%
\column{32}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{l·}\;{}\<[10]%
\>[10]{}\mathbin{:}\;\Varid{t₁}\;\Varid{⟶!}\;\Varid{t₂}\;\Varid{→}\;(\Varid{t₁}\;\Varid{·}\;\Varid{u})\;\Varid{⟶!}\;(\Varid{t₂}\;\Varid{·}\;\Varid{u}){}\<[E]%
\\
\>[3]{}\Varid{·r}\;{}\<[10]%
\>[10]{}\mathbin{:}\;\Varid{u₁}\;\Varid{⟶!}\;\Varid{u₂}\;\Varid{→}\;(\Varid{t}\;\Varid{·}\;\Varid{u₁})\;\Varid{⟶!}\;(\Varid{t}\;\Varid{·}\;\Varid{u₂}){}\<[E]%
\\
\>[3]{}\Varid{λ}\anonymous \;{}\<[10]%
\>[10]{}\mathbin{:}\;\Varid{t₁}\;\Varid{⟶!}\;\Varid{t₂}\;\Varid{→}\;(\Varid{λ}\;\Varid{t₁})\;{}\<[32]%
\>[32]{}\Varid{⟶!}\;(\Varid{λ}\;\Varid{t₂}){}\<[E]%
\\
\>[3]{}\Conid{𝔹-rec₁}\;\mathbin{:}\;\Varid{t₁}\;\Varid{⟶!}\;\Varid{t₂}\;\Varid{→}\;\Conid{𝔹-rec}\;\Varid{t₁}\;\Varid{u}\;\Varid{v}\;\Varid{⟶!}\;\Conid{𝔹-rec}\;\Varid{t₂}\;\Varid{u}\;\Varid{v}{}\<[E]%
\\
\>[3]{}\Conid{𝔹-rec₂}\;\mathbin{:}\;\Varid{u₁}\;\Varid{⟶!}\;\Varid{u₂}\;\Varid{→}\;\Conid{𝔹-rec}\;\Varid{t}\;\Varid{u₁}\;\Varid{v}\;\Varid{⟶!}\;\Conid{𝔹-rec}\;\Varid{t}\;\Varid{u₂}\;\Varid{v}{}\<[E]%
\\
\>[3]{}\Conid{𝔹-rec₃}\;\mathbin{:}\;\Varid{v₁}\;\Varid{⟶!}\;\Varid{v₂}\;\Varid{→}\;\Conid{𝔹-rec}\;\Varid{t}\;\Varid{u}\;\Varid{v₁}\;\Varid{⟶!}\;\Conid{𝔹-rec}\;\Varid{t}\;\Varid{u}\;\Varid{v₂}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
% ---------------------------------------------------------------------------- %

\subsection{Strong Normalisation}

We define strong normalisation in %TODO LINK TO SECTION HERE
but let us recap.

% ---------------------------------------------------------------------------- %
Strong normalisation of spontaneous reduction.
\begin{hscode}\SaveRestoreHook
\ColumnHook
\end{hscode}\resethooks
% ---------------------------------------------------------------------------- %

We prove well-foundedness of this spontaneous reduction relation via 
computability predicates \remarknote{also known
as logical relations, reducibility predicates etc...}. The general 
structure of the proof is based on András Kovacs' 
Agda translation \sidecite{kovacs2020strong} of Jean-Yves Girard's 
strong-normalisation proof for STLC in "Proofs and Types" 
\sidecite{girard1989proofs}. Once we have that spontaneous reduction is
strongly normalising, SN of the conditional reduction relation will follow
immediately. Other properties of this reduction (such as soundness, 
completeness, confluence etc...) will be covered in the next section.

\section{Soundness, Completeness and Confluence}



\setchapterpreamble[u]{\margintoc}

\chapter{Type Theory with Equational Assumptions}
\labch{dependently}

Unlike with the simply typed case, we will delay the settling on concrete syntax
until we have examined several examples. One might find the lack of pinning down
a concrete formal definition of our syntax, conversion, reduction etc...
off-putting and if so, they are encouraged to to skip ahead to section (??).
The trouble is that defining a convenient \remarknote{exactly what I mean by
"convenient" will be explained in said section, but, in short, I would like to
avoid an untyped definition of syntax} syntax for dependent types is
significantly more troublesome.

Still no definition of syntax at all is probably extremely unhelpful, so instead
I present the following typing rules:

...

This definition is incomplete! We haven't defined substitutions (though one
could imagine them as working very similarly to substitutions in STLC) and more
critically, we haven't addressed how to cope with conversion (definitional
equality). Specifically, given terms are now capable of appearing in terms
(see Bool-elim-large) typing rules like application need to require a more
general equality of the domain and argument type than on-the-nose syntactic
equality.

\section{Special Cases}

\subsection{Closed Value Rewrites}

\subsection{Neutral Rewrites}

Neutrals have a nice property: they always block computation. 
This means normal forms are stable under neutral rewrites, and so if we are
able to decide equivalence under a set of neutral equations, this trivially
extends to deciding equivalence modulo the equations extended with beta.

Deciding equality modulo a set of ground equations can be done via ground
completion: ...

\subsection{Constructor-headed Rewrites}

We define constructor-headed rewrites as those of the form

\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[B]{}\Varid{tⁿᵉ}\;\Varid{↦}\;\Varid{c}\;\Varid{u₁}\;\Varid{...}\;\Varid{u₁}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks

where c is a constructor. These are arguably a strict generalisation of closed
value rewrites (section [?]). Unfortunately, the monotonicity of substitution
condition is no longer obviously provable, but neither can we freely (re)orient 
the rules to follow an encompassment ordering: if we rewrite from a term headed
by a constructor, we risk breaking confluence.

...

Luckily, dependent types show us an alternative. We can encode coproducts with
booleans and sigma types. 

CITE KENJI MAILLARD
...

We have developed a procedure to break rewrites of the form 

\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[B]{}\Varid{tⁿᵉ}\;\Varid{↦}\;\Varid{inᵢ}\;\Varid{u₁}\;\Varid{...}\;\Varid{u₁}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks

into a combination of closed value and neutral rewrites.

The occurs check

\subsection{Infinitary Types}

We have shown that equations between terms of first-order finitary types can be 
decomposed into more primitive building blocks, but we might hope to extend this
also to infinitary types, such as natural numbers, lists, trees
etc...

Eliminators for these types express their recursion/induction principles. To
destruct arbitrarily nested structures with a single invocation of the
eliminator, recursive occurences of the type in constructors are replaced with
the motive type.

% Formal definition of ℕ-rec
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[B]{}\mbox{\onelinecomment  In STLC, we can type the recursion principle for ℕs as}{}\<[E]%
\\
\>[B]{}\Conid{ℕ-rec}\;\mathbin{:}\;\Conid{Tm}\;\Conid{Γ}\;\Conid{A}\;\Varid{→}\;\Conid{Tm}\;(\Conid{Γ}\;\Varid{,}\;\Conid{A})\;\Conid{A}\;\Varid{→}\;\Conid{Tm}\;\Conid{Γ}\;\Conid{ℕ}\;\Varid{→}\;\Conid{Tm}\;\Conid{Γ}\;\Conid{A}{}\<[E]%
\\[\blanklineskip]%
\>[B]{}\mbox{\onelinecomment  In dependently typed lambda calculus, we can define the induction principle}{}\<[E]%
\\
\>[B]{}\Conid{ℕ-ind}\;\mathbin{:}\;(\Conid{P}\;\mathbin{:}\;\Conid{Ty}\;(\Conid{Γ}\;\Varid{,}\;\Conid{ℕ}))\;\Varid{→}\;\Conid{Tm}\;\Conid{Γ}\;(\Conid{P}\;[\mskip1.5mu \;\Varid{<}\;\Varid{zero}\;\Varid{>}\;\mskip1.5mu])\;\Varid{→}\;\Conid{Tm}\;\Conid{Γ}\;\Conid{ℕ}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks


Arguably, the flat case constructs we have examined so far are
also recursors/induction principles, only the structure of the types in those
cases wasn't actually recursive, but there are important implications w.r.t.
smart case.


Induction poses some slight difficulties though. First of all, while induction
principles look a lot like the flat case constructs used to eliminate coproducts
their meaning is somewhat different. When inducting on natural numbers, we will
always eventually hit the base (zero) case irrespective of the input, so we
cannot soundly assume 'scrutinee = zero', even propositionally.
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[B]{}\Conid{COUNTER}\;\Conid{EXAMPLE}\;\Conid{HERE>}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
One could argue that in the 'suc'cessor case, we know the input natural number
must start with 'suc', but this is heavily reliant on the rest of the datatype.
If we instead inducted on a type of unnormalised integers:

\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[B]{}\Keyword{data}\;\Conid{ℤ}\;\mathbin{:}\;\Keyword{Type}\;\Keyword{where}{}\<[E]%
\\
\>[B]{}\hsindent{3}{}\<[3]%
\>[3]{}\Varid{su}\;\mathbin{:}\;\Conid{ℤ}\;\Varid{→}\;\Conid{ℤ}{}\<[E]%
\\
\>[B]{}\hsindent{3}{}\<[3]%
\>[3]{}\Varid{pr}\;\mathbin{:}\;\Conid{ℤ}\;\Varid{→}\;\Conid{ℤ}{}\<[E]%
\\
\>[B]{}\hsindent{3}{}\<[3]%
\>[3]{}\Varid{ze}\;\mathbin{:}\;\Conid{ℤ}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks

In the successor/predecessor cases, we can infer that the scrutinee must start 
with 'su' or 'pr' (i.e. it is definitely not 'ze') but that is not enough to
give us a unique value to rewrite to.

I therefore argue it is somewhat meaningless to try and integerate these 
equational assumptions with general inductive principles. However, sometimes
users may not wish to induct on an inductive type but merely do a case split,
splitting on a finite number of choices.

\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{16}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[B]{}\Varid{is-zero}\;\mathbin{:}\;\Conid{ℕ}\;\Varid{→}\;\Conid{Bool}{}\<[E]%
\\
\>[B]{}\Varid{is-zero}\;\Varid{ze}\;{}\<[16]%
\>[16]{}\colonequiv\;\Varid{true}{}\<[E]%
\\
\>[B]{}\Varid{is-zero}\;(\Varid{su}\;\anonymous )\;\colonequiv\;\Varid{false}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks

Elaborating such situations into pattern matches with coproducts is not too
tricky. Taking the view of inductive datatypes as fixpoints of strictly 
positive functors - the "initial algebra" - gives us 'fix : F (Fix F) → Fix F' 
and 'unfix : Fix F → F (Fix F)'. The initial algebra of 'ℕ' is 'λ X → 1 + X',
so we have
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{16}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[B]{}\Varid{unfix-ℕ}\;\mathbin{:}\;\Conid{ℕ}\;\Varid{→}\;\Varid{⊤}\;\Varid{+}\;\Conid{ℕ}{}\<[E]%
\\
\>[B]{}\Varid{unfix-ℕ}\;\Varid{ze}\;{}\<[16]%
\>[16]{}\colonequiv\;\Varid{inl}\;\Varid{tt}{}\<[E]%
\\
\>[B]{}\Varid{unfix-ℕ}\;(\Varid{su}\;\Varid{n})\;\colonequiv\;\Varid{inr}\;\Varid{n}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks

And now we can reuse our approach for dealing with coproducts (every
case split on a natural number 't' can be elaborated into a case split on
the coproduct 'unfix t'). 

There is perhaps one obvious limitation here: while repeated case splits on the
same natural number will reduce through iterated rewriting, any rewrite rule
'unfix t → u' will never fire on 't' itself. Consider

\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{9}{@{}>{\hspre}l<{\hspost}@{}}%
\column{12}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[B]{}\Varid{case}\;\Varid{t}\;\Varid{of}\;{}\<[E]%
\\
\>[B]{}\hsindent{3}{}\<[3]%
\>[3]{}\Varid{ze}\;\Varid{→}\;\Keyword{let}\;\Varid{foo}\;\mathbin{:}\;\Varid{t}\;=\;\Varid{ze}{}\<[E]%
\\
\>[3]{}\hsindent{9}{}\<[12]%
\>[12]{}\Varid{foo}\;\colonequiv\;\Varid{refl}{}\<[E]%
\\
\>[3]{}\hsindent{6}{}\<[9]%
\>[9]{}\Keyword{in}\;\Varid{...}{}\<[E]%
\\
\>[B]{}\hsindent{3}{}\<[3]%
\>[3]{}\Varid{su}\;\anonymous \;\Varid{→}\;\Varid{...}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks

\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{8}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[B]{}\Varid{case}\;\Varid{t}\;\Varid{of}\;{}\<[E]%
\\
\>[B]{}\hsindent{3}{}\<[3]%
\>[3]{}\Varid{ze}\;{}\<[8]%
\>[8]{}\Varid{→}\;\Conid{ℕ-elim}\;\Varid{t}\;\Varid{?0}\;\Varid{?1}\;{}\<[E]%
\\
\>[B]{}\hsindent{3}{}\<[3]%
\>[3]{}\Varid{su}\;\Varid{n}\;\Varid{→}\;\Varid{?2}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks

We can fix both of these problems by building 'fix'/'unfix' into the syntax 
more deeply and not including raw neutrals of type 'ℕ' in normal forms.

Instead, we add the rule

Γ ⊢ⁿᵉ t : ⊤ + ℕ
---------------
Γ ⊢ⁿᶠ fix t : ℕ

Now neutrals 'tⁿᵉ : A' reduce to 'fix (unfix tⁿᵉ) : A', and rewrites targetting
'unfix tⁿᵉ' can fire.

Inductive types bring up one final concern: what if an equation is recursive?
For example 't = su t'. I consider cases:
- Raw 't = su t' equations: we can label the current match branch as impossible.
  Note Agda already rejects cyclic equations involving variables: we merely
  need to extend this to neutral terms by running a conversion check between the
  LHS and each argument to the constructor on the RHS.
- 't = su (f t)' where 'f t' is a neutral blocked on 'f'. These cases can
  be decomposed
- 't = su (f t)' where 'f t' is a neutral blocked on 't'. Now we are in trouble.
  TODO: This isn't really possible in the sense that 'f' cannot be a function
  here. It has to be an eliminator of some form.

\section{Categories with Families}




This should be obvious - but if we use a quotiented syntax, that means we have
to go reduction-free (citation needed - I'm not actually convinced this is true
lol)


\subsection{Strictification}

\subsection{Mechanisation}
\setchapterpreamble[u]{\margintoc}

\chapter{Plan}
\labch{plan}


%% bibliography
% \bibliographystyle{apa}
\setchapterstyle{plain} % Output plain chapters from this point onwards
\pagelayout{wide}
\printbibliography[heading=bibintoc, title=Bibliography]


\end{document}
